{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import scipy.stats as stats\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Adjust paths to project structure\n",
    "sys.path.append(os.path.abspath(\"../../\"))\n",
    "\n",
    "from utils.data.curating_stooq import curate_stooq_dir_5min\n",
    "from utils.data.jump_detection import detect_jumps_many, get_cojumps, compute_u_shape\n",
    "from model.wavelet.wavelet import WaveletModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb89fba",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 1) LOAD DATA\n",
    "# ==================================================================================\n",
    "data_dir = \"/home/janis/4A/timeseries/data/stooq/hungary/\"\n",
    "# Note: Paper uses 1-min data. We are using 5-min data here.\n",
    "dfs = curate_stooq_dir_5min(data_dir, pattern=\"*.txt\", recursive=True, tz=None)\n",
    "print(f\"Loaded {len(dfs)} tickers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5083ca",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 2) HELPER FUNCTIONS (Time Filtering & Returns)\n",
    "# ==================================================================================\n",
    "\n",
    "def filter_trading_hours(df: pd.DataFrame, remove_start_min: int = 0, remove_end_min: int = 0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters the dataframe to remove the first N minutes and last M minutes of each trading day.\n",
    "    \"\"\"\n",
    "    if df.empty: return df\n",
    "    \n",
    "    # Efficiently filter by time of day if possible, or iterate by day\n",
    "    # Iterating by day is safer for varying market hours, but slower.\n",
    "    # Here we assume standard intraday data.\n",
    "    \n",
    "    grouped = df.groupby(df.index.date)\n",
    "    filtered_days = []\n",
    "    \n",
    "    for date, day_df in grouped:\n",
    "        if len(day_df) <= 2: continue\n",
    "        day_df = day_df.sort_index()\n",
    "        \n",
    "        start_time = day_df.index[0] + pd.Timedelta(minutes=remove_start_min)\n",
    "        end_time = day_df.index[-1] - pd.Timedelta(minutes=remove_end_min)\n",
    "        \n",
    "        mask = (day_df.index >= start_time) & (day_df.index <= end_time)\n",
    "        filtered_days.append(day_df[mask])\n",
    "        \n",
    "    if not filtered_days: return pd.DataFrame()\n",
    "    return pd.concat(filtered_days)\n",
    "\n",
    "def get_log_returns(df: pd.DataFrame, price_col=\"close\") -> pd.Series:\n",
    "    \"\"\"Computes log returns: ln(P_t / P_{t-1})\"\"\"\n",
    "    return np.log(df[price_col] / df[price_col].shift(1)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1595b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 3) SCENARIO DEFINITIONS & DISTRIBUTION ANALYSIS\n",
    "# ==================================================================================\n",
    "# Paper methodology: \"considering only what happened between 10:30 and 15:00\"\n",
    "# US Market Open 9:30, Close 16:00. \n",
    "# 10:30 is +60min (Skip first hour). 15:00 is -60min (Skip last hour).\n",
    "\n",
    "scenarios = {\n",
    "    \"Full Day\": (0, 0),\n",
    "    \"No Open/Close (30m)\": (30, 30),\n",
    "    \"No Open/Close (1h)\": (60, 60)  # Approximates Paper's selection\n",
    "}\n",
    "\n",
    "# Pick a sample ticker for distribution visualization\n",
    "sample_ticker = next(iter(dfs)) if dfs else None\n",
    "for t, d in dfs.items():\n",
    "    if len(d) > 1000:\n",
    "        sample_ticker = t\n",
    "        break\n",
    "\n",
    "if sample_ticker:\n",
    "    print(f\"Using {sample_ticker} for distribution plots.\")\n",
    "    df_sample = dfs[sample_ticker]\n",
    "    \n",
    "    fig_dist = go.Figure()\n",
    "    \n",
    "    for name, (trim_start, trim_end) in scenarios.items():\n",
    "        df_filtered = filter_trading_hours(df_sample, trim_start, trim_end)\n",
    "        log_rets = get_log_returns(df_filtered)\n",
    "        \n",
    "        # Standardize\n",
    "        z_scores = (log_rets - log_rets.mean()) / log_rets.std()\n",
    "        \n",
    "    fig_dist.add_trace(go.Histogram(\n",
    "            x=z_scores,\n",
    "            name=f\"{name} (std={log_rets.std():.5f})\",\n",
    "        histnorm='probability density',\n",
    "            opacity=0.5,\n",
    "            nbinsx=100\n",
    "    ))\n",
    "        \n",
    "    x_range = np.linspace(-6, 6, 200)\n",
    "    fig_dist.add_trace(go.Scatter(\n",
    "        x=x_range, y=stats.norm.pdf(x_range, 0, 1),\n",
    "        mode='lines', name='Normal(0,1)', line=dict(color='black', dash='dash')\n",
    "    ))\n",
    "    \n",
    "    fig_dist.update_layout(\n",
    "        title=f\"Log Return Distribution (Standardized) - {sample_ticker}\",\n",
    "        xaxis_title=\"Z-Score\",\n",
    "        yaxis_title=\"Density\",\n",
    "        barmode='overlay',\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig_dist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 4) JUMP DETECTION ON SCENARIOS & TIMING ANALYSIS\n",
    "# ==================================================================================\n",
    "jump_results = {}\n",
    "\n",
    "for name, (trim_start, trim_end) in scenarios.items():\n",
    "    print(f\"Running detection for: {name}...\")\n",
    "    # Filter all\n",
    "    filtered_dfs = {t: filter_trading_hours(d, trim_start, trim_end) for t, d in dfs.items() if not d.empty}\n",
    "    # Detect\n",
    "    jumps_df = detect_jumps_many(filtered_dfs, threshold=4.0)\n",
    "    jump_results[name] = jumps_df\n",
    "    print(f\"  -> Detected {len(jumps_df)} jumps.\")\n",
    "\n",
    "# Plot Time of Day Distribution\n",
    "fig_time = go.Figure()\n",
    "for name, j_df in jump_results.items():\n",
    "    if j_df.empty: continue\n",
    "    # Decimal hour\n",
    "    times = j_df[\"timestamp\"].dt.hour + j_df[\"timestamp\"].dt.minute / 60.0\n",
    "    fig_time.add_trace(go.Histogram(\n",
    "        x=times, name=name, xbins=dict(size=0.25), opacity=0.6\n",
    "    ))\n",
    "\n",
    "fig_time.update_layout(\n",
    "    title=\"Jump Occurrence by Time of Day\",\n",
    "    xaxis_title=\"Hour of Day\",\n",
    "    yaxis_title=\"Count\",\n",
    "    barmode='group',\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig_time.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177fa3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 5) TIMING CLARIFICATION (Zoom Plot)\n",
    "# ==================================================================================\n",
    "# Clarification: The marker at T is the return (T-1 -> T). \n",
    "full_jumps = jump_results.get(\"Full Day\")\n",
    "if full_jumps is not None and not full_jumps.empty:\n",
    "    # Pick max score jump\n",
    "    sample_jump = full_jumps.iloc[full_jumps[\"score\"].abs().argmax()]\n",
    "    t_jump = sample_jump[\"timestamp\"]\n",
    "    ticker = sample_jump[\"ticker\"]\n",
    "    \n",
    "    df_viz = dfs[ticker]\n",
    "    if t_jump in df_viz.index:\n",
    "        loc = df_viz.index.get_loc(t_jump)\n",
    "        start_loc = max(0, loc - 6)\n",
    "        end_loc = min(len(df_viz), loc + 7)\n",
    "        df_zoom = df_viz.iloc[start_loc:end_loc]\n",
    "        \n",
    "        fig_zoom = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "        fig_zoom.add_trace(go.Scatter(x=df_zoom.index, y=df_zoom[\"close\"], mode='lines+markers', name='Price'), secondary_y=False)\n",
    "        \n",
    "        # Jump Marker\n",
    "        fig_zoom.add_trace(\n",
    "            go.Scatter(x=[t_jump], y=[sample_jump[\"score\"]], mode=\"markers+text\", name=\"Jump Score\",\n",
    "                       marker=dict(symbol=\"triangle-up\", size=15, color=\"red\"),\n",
    "                       text=[\"Jump Detected<br>(Return ending here)\"], textposition=\"top center\"),\n",
    "            secondary_y=True\n",
    "        )\n",
    "        fig_zoom.update_layout(title=f\"Zoom on Jump: {ticker} at {t_jump}\", template=\"plotly_white\")\n",
    "        fig_zoom.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c03cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 6) PAPER REPRODUCTION: WAVELET CLASSIFICATION\n",
    "# ==================================================================================\n",
    "# We use the \"No Open/Close (1h)\" scenario as it matches the paper's \"10:30 - 15:00\" window best.\n",
    "jumps_for_analysis = jump_results.get(\"No Open/Close (1h)\")\n",
    "if jumps_for_analysis is None or jumps_for_analysis.empty:\n",
    "    print(\"No jumps found in 1h-trimmed dataset. Falling back to Full Day.\")\n",
    "    jumps_for_analysis = jump_results.get(\"Full Day\")\n",
    "\n",
    "# 6a) Extract Windows x(t)\n",
    "def extract_jump_windows(jumps_df: pd.DataFrame, dfs: Dict[str, pd.DataFrame], window_steps: int = 12):\n",
    "    windows = []\n",
    "    valid_indices = []\n",
    "    for idx, row in jumps_df.iterrows():\n",
    "        ticker, ts = row[\"ticker\"], row[\"timestamp\"]\n",
    "        if ticker not in dfs: continue\n",
    "        df = dfs[ticker]\n",
    "        if ts not in df.index: continue\n",
    "        \n",
    "        loc = df.index.get_loc(ts)\n",
    "        if loc - window_steps < 0 or loc + window_steps + 1 > len(df): continue\n",
    "        \n",
    "        subset = df.iloc[loc - window_steps : loc + window_steps + 1]\n",
    "        # Normalized return profile: r(t) / (f * sigma)\n",
    "        # We use the jump's stored f/sigma for normalization to preserve relative shape\n",
    "        norm = row[\"f\"] * row[\"sigma\"]\n",
    "        if norm == 0: norm = 1e-4\n",
    "            \n",
    "        x_profile = subset[\"close\"].pct_change().fillna(0.0).values / norm\n",
    "        \n",
    "        # Align jump direction (center is at index `window_steps`)\n",
    "        jump_sign = np.sign(x_profile[window_steps])\n",
    "        if jump_sign == 0: jump_sign = 1\n",
    "        \n",
    "        windows.append(x_profile * jump_sign)\n",
    "        valid_indices.append(idx)\n",
    "        \n",
    "    return jumps_df.loc[valid_indices].copy(), np.array(windows)\n",
    "\n",
    "print(\"Extracting windows for classification...\")\n",
    "jumps_subset, X_windows = extract_jump_windows(jumps_for_analysis, dfs, window_steps=12)\n",
    "print(f\"Extracted {len(X_windows)} windows.\")\n",
    "\n",
    "# 6b) Compute D1, D2, D3\n",
    "if len(X_windows) > 0:\n",
    "    # D1: Reflexivity (Wavelet Model)\n",
    "    # J=3 is appropriate for T=25 (5-min data) vs J=6 for T=119 (1-min data)\n",
    "    wm = WaveletModel(n_layers=0, n_neurons=0, n_outputs=0, J=3, n_components=3)\n",
    "    embedding = wm.fit_transform(X_windows)\n",
    "    jumps_subset[\"D1_reflexivity\"] = embedding[:, 0]\n",
    "    \n",
    "    # Check orientation of D1 (Positive should be Exogenous/Post-activity)\n",
    "    center = X_windows.shape[1] // 2\n",
    "    post_activity = np.sum(np.abs(X_windows[:, center+1:]), axis=1)\n",
    "    pre_activity = np.sum(np.abs(X_windows[:, :center]), axis=1)\n",
    "    asymmetry = (post_activity - pre_activity) / (post_activity + pre_activity + 1e-6)\n",
    "    \n",
    "    corr = np.corrcoef(jumps_subset[\"D1_reflexivity\"], asymmetry)[0, 1]\n",
    "    if corr < 0:\n",
    "        jumps_subset[\"D1_reflexivity\"] *= -1\n",
    "        \n",
    "    # D2: Mean Reversion & D3: Trend (Handcrafted Filters)\n",
    "    # Refined based on Paper Section III.C and III.D\n",
    "    # D2 (Mean Reversion): Captures V-shape.\n",
    "    # Paper: \"positive value of x(-1) and negative value of x(1)\" (for jump-aligned x)\n",
    "    # We use x(center-1) - x(center+1). Positive => Pre-jump Up, Post-jump Down.\n",
    "    jumps_subset[\"D2_mean_reversion\"] = X_windows[:, center - 1] - X_windows[:, center + 1]\n",
    "\n",
    "    # D3 (Trend): Captures Persistent Trend.\n",
    "    # We use x(center-1) + x(center+1). Positive => Pre-jump Up, Post-jump Up.\n",
    "    jumps_subset[\"D3_trend\"] = X_windows[:, center - 1] + X_windows[:, center + 1]\n",
    "\n",
    "    # 6c) Plot Projections\n",
    "    fig_mr = px.scatter(\n",
    "        jumps_subset, x=\"D1_reflexivity\", y=\"D2_mean_reversion\", color=\"D2_mean_reversion\",\n",
    "        title=\"<b>Reflexivity vs Mean-Reversion</b> (Paper Fig 5 equivalent)\",\n",
    "        labels={\"D1_reflexivity\": \"D1 (Reflexivity)\", \"D2_mean_reversion\": \"D2 (Mean Reversion)\"},\n",
    "        color_continuous_scale=\"RdBu\", opacity=0.6\n",
    "    )\n",
    "    fig_mr.add_vline(x=0, line_dash=\"dash\"); fig_mr.add_hline(y=0, line_dash=\"dash\")\n",
    "    fig_mr.update_layout(template=\"plotly_white\")\n",
    "    fig_mr.show()\n",
    "    \n",
    "    fig_tr = px.scatter(\n",
    "        jumps_subset, x=\"D1_reflexivity\", y=\"D3_trend\", color=\"D3_trend\",\n",
    "        title=\"<b>Reflexivity vs Trend</b> (Paper Fig 6 equivalent)\",\n",
    "        labels={\"D1_reflexivity\": \"D1 (Reflexivity)\", \"D3_trend\": \"D3 (Trend)\"},\n",
    "        color_continuous_scale=\"Viridis\", opacity=0.6\n",
    "    )\n",
    "    fig_tr.add_vline(x=0, line_dash=\"dash\"); fig_tr.add_hline(y=0, line_dash=\"dash\")\n",
    "    fig_tr.update_layout(template=\"plotly_white\")\n",
    "    fig_tr.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
