{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db96cf42",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Non-interactive backend\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "from scipy import stats as scipy_stats\n",
    "\n",
    "# Add project root to path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), \"../../\"))\n",
    "except NameError:\n",
    "    project_root = os.path.abspath(\"../../\")\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from utils.data.curating_stooq import curate_stooq_dir_5min\n",
    "from utils.data.jump_detection import detect_jumps_many\n",
    "from model.wavelet.wavelet import WaveletModel\n",
    "from plot_utils import save_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef8ba9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_profiles(X_windows, jumps_subset, output_dir, name):\n",
    "    \"\"\"\n",
    "    Plots average temporal profiles along PCA directions.\n",
    "    X-axis is time relative to jump (centered at 0).\n",
    "    \"\"\"\n",
    "    directions = [\"D1_reflexivity\", \"D2_mean_reversion\", \"D3_trend\"]\n",
    "    center = X_windows.shape[1] // 2\n",
    "    t_axis = np.arange(-center, center + 1)\n",
    "    \n",
    "    for dim in directions:\n",
    "        if dim not in jumps_subset.columns: continue\n",
    "        \n",
    "        scores = jumps_subset[dim].values\n",
    "        sorted_idx = np.argsort(scores)\n",
    "        X_sorted = X_windows[sorted_idx]\n",
    "        n = len(scores)\n",
    "        \n",
    "        # Quantiles to visualize (Low, Mid, High)\n",
    "        quantiles = [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(quantiles)-1))\n",
    "        \n",
    "        for i in range(len(quantiles)-1):\n",
    "            q_s, q_e = quantiles[i], quantiles[i+1]\n",
    "            idx_s, idx_e = int(q_s*n), int(q_e*n)\n",
    "            if idx_e <= idx_s: continue\n",
    "            \n",
    "            avg = np.mean(X_sorted[idx_s:idx_e], axis=0)\n",
    "            ax.plot(t_axis, avg, linewidth=2, label=f\"Q {q_s}-{q_e}\", color=colors[i])\n",
    "            \n",
    "        ax.axvline(x=0, linestyle='--', color='red', alpha=0.7, label='Jump')\n",
    "        ax.set_xlabel(\"Time (steps)\")\n",
    "        ax.set_ylabel(\"Normalized Return x(t)\")\n",
    "        ax.set_title(f\"Average Profiles along {dim} - {name}\\n(X-axis: Time relative to Jump)\")\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        out_path = os.path.join(output_dir, f\"{name}_profile_{dim}.html\")\n",
    "        print(f\"    Saved profile plot to {out_path}\")\n",
    "        save_plot(fig, f\"reproduce_poland_profile_{dim}\", format='pdf')\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b61c061",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_analysis_for_subset(\n",
    "    dfs_subset: dict, \n",
    "    subset_name: str, \n",
    "    output_dir: str, \n",
    "    window_steps: int = 12\n",
    "):\n",
    "    print(f\"\\n=== Running Analysis for {subset_name} ({len(dfs_subset)} stocks) ===\")\n",
    "    \n",
    "    # 1. Filter Trading Hours (10:30 - 15:00 approx)\n",
    "    # Remove first/last 60 mins from each day\n",
    "    print(\"  Filtering trading hours...\")\n",
    "    filtered_dfs = {}\n",
    "    total_days = 0\n",
    "    for ticker, df in dfs_subset.items():\n",
    "        days = []\n",
    "        for date, day_df in df.groupby(df.index.date):\n",
    "            if len(day_df) <= 12: continue\n",
    "            day_df = day_df.sort_index()\n",
    "            \n",
    "            # For 5-min bars, 60 mins = 12 bars\n",
    "            start = day_df.index[0] + pd.Timedelta(minutes=60)\n",
    "            end = day_df.index[-1] - pd.Timedelta(minutes=60)\n",
    "            \n",
    "            mask = (day_df.index >= start) & (day_df.index <= end)\n",
    "            if mask.any():\n",
    "                days.append(day_df[mask])\n",
    "        \n",
    "        if days:\n",
    "            filtered_dfs[ticker] = pd.concat(days)\n",
    "            total_days += len(days)\n",
    "\n",
    "    if not filtered_dfs:\n",
    "        print(\"  No data remaining after filtering.\")\n",
    "        return\n",
    "\n",
    "    # 2. Detect Jumps\n",
    "    print(\"  Detecting jumps...\")\n",
    "    jumps_df = detect_jumps_many(filtered_dfs, threshold=4.0)\n",
    "    print(f\"  Detected {len(jumps_df)} total jumps.\")\n",
    "    \n",
    "    if len(jumps_df) < 50:\n",
    "        print(\"  Not enough jumps for robust PCA (need > 50).\")\n",
    "        return\n",
    "\n",
    "    # 3. Extract Windows\n",
    "    print(\"  Extracting windows...\")\n",
    "    windows = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for idx, row in jumps_df.iterrows():\n",
    "        ticker, ts = row[\"ticker\"], row[\"timestamp\"]\n",
    "        if ticker not in filtered_dfs: continue\n",
    "        df = filtered_dfs[ticker]\n",
    "        \n",
    "        if ts not in df.index: continue\n",
    "        loc = df.index.get_loc(ts)\n",
    "        \n",
    "        if loc - window_steps < 0 or loc + window_steps + 1 > len(df): continue\n",
    "        \n",
    "        subset = df.iloc[loc - window_steps : loc + window_steps + 1]\n",
    "        \n",
    "        # Normalization\n",
    "        norm = row[\"f\"] * row[\"sigma\"]\n",
    "        if norm == 0: norm = 1e-4\n",
    "            \n",
    "        r_window = subset[\"close\"].pct_change().fillna(0.0).values\n",
    "        x_profile = r_window / norm\n",
    "        \n",
    "        # Align Jump Direction (Paper convention: Jump > 0)\n",
    "        # Center is at index `window_steps`\n",
    "        jump_sign = np.sign(x_profile[window_steps])\n",
    "        if jump_sign == 0: jump_sign = 1\n",
    "        \n",
    "        windows.append(x_profile * jump_sign)\n",
    "        valid_indices.append(idx)\n",
    "        \n",
    "    X_windows = np.array(windows)\n",
    "    jumps_subset = jumps_df.loc[valid_indices].copy()\n",
    "    print(f\"  Extracted {len(X_windows)} valid windows.\")\n",
    "\n",
    "    # 4. Wavelet PCA\n",
    "    print(\"  Running Wavelet Kernel PCA...\")\n",
    "    wm = WaveletModel(n_layers=0, n_neurons=0, n_outputs=0, J=3, n_components=3)\n",
    "    embedding = wm.fit_transform(X_windows)\n",
    "    \n",
    "    d1 = embedding[:, 0]\n",
    "    \n",
    "    # Orient D1 (Reflexivity): Positive should correlate with Post-Jump Activity\n",
    "    center = window_steps\n",
    "    act_post = np.sum(np.abs(X_windows[:, center+1:]), axis=1)\n",
    "    act_pre = np.sum(np.abs(X_windows[:, :center]), axis=1)\n",
    "    asymmetry = (act_post - act_pre) / (act_post + act_pre + 1e-6)\n",
    "    \n",
    "    corr = np.corrcoef(d1, asymmetry)[0, 1]\n",
    "    if corr < 0:\n",
    "        print(f\"  Flipping D1 sign (correlation was {corr:.2f})\")\n",
    "        d1 *= -1\n",
    "        corr = -corr  # Update correlation after flipping\n",
    "        \n",
    "    jumps_subset[\"D1_reflexivity\"] = d1\n",
    "    jumps_subset[\"asymmetry\"] = asymmetry\n",
    "    print(f\"  D1-Asymmetry correlation: {corr:.3f}\")\n",
    "    \n",
    "    # Handcrafted Features\n",
    "    # D2 (Mean Reversion): Pre-Jump - Post-Jump\n",
    "    # D3 (Trend): Pre-Jump + Post-Jump\n",
    "    # t = +/- 1 step from center\n",
    "    jumps_subset[\"D2_mean_reversion\"] = X_windows[:, center - 1] - X_windows[:, center + 1]\n",
    "    jumps_subset[\"D3_trend\"] = X_windows[:, center - 1] + X_windows[:, center + 1]\n",
    "\n",
    "    # 5. Generate Plots\n",
    "    print(\"  Generating plots...\")\n",
    "    \n",
    "    # Scatter Plot: D1 vs Asymmetry (to verify separation)\n",
    "    slope, intercept, r_value, p_value, std_err = scipy_stats.linregress(\n",
    "        jumps_subset[\"asymmetry\"], jumps_subset[\"D1_reflexivity\"]\n",
    "    )\n",
    "    \n",
    "    fig_asym, ax_asym = plt.subplots(figsize=(10, 8))\n",
    "    scatter = ax_asym.scatter(jumps_subset[\"asymmetry\"], jumps_subset[\"D1_reflexivity\"], \n",
    "                              c=jumps_subset[\"asymmetry\"], cmap='RdBu_r', alpha=0.6, s=20)\n",
    "    \n",
    "    # Add regression line\n",
    "    asym_range = np.linspace(jumps_subset[\"asymmetry\"].min(), jumps_subset[\"asymmetry\"].max(), 100)\n",
    "    reg_line = slope * asym_range + intercept\n",
    "    ax_asym.plot(asym_range, reg_line, 'r--', linewidth=2, label=f'Regression (R²={r_value**2:.3f})')\n",
    "    \n",
    "    ax_asym.axvline(x=0, linestyle='--', color='gray', alpha=0.5, label='Symmetric')\n",
    "    ax_asym.axhline(y=0, linestyle='--', color='gray', alpha=0.5)\n",
    "    plt.colorbar(scatter, ax=ax_asym, label='Asymmetry')\n",
    "    \n",
    "    ax_asym.set_xlabel(\"Asymmetry (Post-Pre)/(Post+Pre)\")\n",
    "    ax_asym.set_ylabel(\"D1 (Reflexivity)\")\n",
    "    ax_asym.set_title(f\"D1 (Reflexivity) vs Asymmetry ({subset_name}, N={len(X_windows)})\\nCorrelation: {corr:.3f}, R²: {r_value**2:.3f}\")\n",
    "    ax_asym.legend()\n",
    "    ax_asym.grid(True, alpha=0.3)\n",
    "    \n",
    "    out_path_asym = os.path.join(output_dir, f\"{subset_name}_D1_asymmetry.html\")\n",
    "    print(f\"    Saved D1-Asymmetry plot to {out_path_asym}\")\n",
    "    save_plot(fig_asym, f\"reproduce_poland_D1_asymmetry\", format='pdf')\n",
    "    plt.close(fig_asym)\n",
    "    \n",
    "    # Scatter Plot: D1 vs D2 (Mean-Reversion) - Fig 5 equivalent\n",
    "    fig_mr, ax_mr = plt.subplots(figsize=(10, 8))\n",
    "    scatter_mr = ax_mr.scatter(jumps_subset[\"D1_reflexivity\"], jumps_subset[\"D2_mean_reversion\"], \n",
    "                               c=jumps_subset[\"D2_mean_reversion\"], cmap='RdBu_r', alpha=0.5, s=20)\n",
    "    ax_mr.axvline(x=0, linestyle='--', color='gray', alpha=0.5)\n",
    "    ax_mr.axhline(y=0, linestyle='--', color='gray', alpha=0.5)\n",
    "    plt.colorbar(scatter_mr, ax=ax_mr, label='D2 Mean-Reversion')\n",
    "    ax_mr.set_xlabel(\"D1 Reflexivity\")\n",
    "    ax_mr.set_ylabel(\"D2 Mean-Reversion\")\n",
    "    ax_mr.set_title(f\"Reflexivity vs Mean-Reversion ({subset_name}, N={len(X_windows)})\")\n",
    "    ax_mr.grid(True, alpha=0.3)\n",
    "    \n",
    "    out_path_scatter = os.path.join(output_dir, f\"{subset_name}_fig5_mr.html\")\n",
    "    print(f\"    Saved scatter plot to {out_path_scatter}\")\n",
    "    save_plot(fig_mr, f\"reproduce_poland_fig5_mr\", format='pdf')\n",
    "    plt.close(fig_mr)\n",
    "    \n",
    "    # Scatter Plot: D1 vs D3 (Trend) - Fig 6 equivalent\n",
    "    fig_tr, ax_tr = plt.subplots(figsize=(10, 8))\n",
    "    scatter_tr = ax_tr.scatter(jumps_subset[\"D1_reflexivity\"], jumps_subset[\"D3_trend\"], \n",
    "                               c=jumps_subset[\"D3_trend\"], cmap='viridis', alpha=0.5, s=20)\n",
    "    ax_tr.axvline(x=0, linestyle='--', color='gray', alpha=0.5)\n",
    "    ax_tr.axhline(y=0, linestyle='--', color='gray', alpha=0.5)\n",
    "    plt.colorbar(scatter_tr, ax=ax_tr, label='D3 Trend')\n",
    "    ax_tr.set_xlabel(\"D1 Reflexivity\")\n",
    "    ax_tr.set_ylabel(\"D3 Trend\")\n",
    "    ax_tr.set_title(f\"Reflexivity vs Trend ({subset_name}, N={len(X_windows)})\")\n",
    "    ax_tr.grid(True, alpha=0.3)\n",
    "    \n",
    "    out_path_scatter_tr = os.path.join(output_dir, f\"{subset_name}_fig6_tr.html\")\n",
    "    print(f\"    Saved scatter plot to {out_path_scatter_tr}\")\n",
    "    save_plot(fig_tr, f\"reproduce_poland_fig6_tr\", format='pdf')\n",
    "    plt.close(fig_tr)\n",
    "    \n",
    "    # Profile Plots (all three directions)\n",
    "    plot_profiles(X_windows, jumps_subset, output_dir, subset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c58366",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Poland data directory\n",
    "    data_dir = \"/home/janis/4A/timeseries/data/stooq/poland/5_min/pl/wsestocks\"\n",
    "    print(f\"Loading Poland data from {data_dir}...\")\n",
    "    all_dfs = curate_stooq_dir_5min(data_dir, pattern=\"*.txt\", recursive=True)\n",
    "    \n",
    "    # Filter to stocks with enough data (e.g., > 1000 points) to ensure meaningful jumps\n",
    "    valid_tickers = [t for t, d in all_dfs.items() if len(d) > 500]\n",
    "    print(f\"Found {len(valid_tickers)} valid tickers.\")\n",
    "    \n",
    "    if not valid_tickers:\n",
    "        print(\"No valid data found.\")\n",
    "        return\n",
    "    \n",
    "    # Sort by data length to pick the best ones\n",
    "    valid_tickers.sort(key=lambda t: len(all_dfs[t]), reverse=True)\n",
    "    \n",
    "    # Select Subsets\n",
    "    # 1. Small Subset: Top 5 most liquid/long stocks\n",
    "    tickers_5 = valid_tickers\n",
    "    dfs_5 = {t: all_dfs[t] for t in tickers_5}\n",
    "    \n",
    "    # 2. Large Subset: Top 30 (or all if less)\n",
    "    limit_30 = max(80, len(valid_tickers))\n",
    "    tickers_30 = valid_tickers[:limit_30]\n",
    "    dfs_30 = {t: all_dfs[t] for t in tickers_30}\n",
    "    \n",
    "    # Output Directory\n",
    "    try:\n",
    "        base_dir = os.path.dirname(__file__)\n",
    "    except NameError:\n",
    "        base_dir = os.getcwd()\n",
    "    output_dir = os.path.join(base_dir, \"poland_outputs\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Run Comparisons\n",
    "    run_analysis_for_subset(dfs_5, \"5_Stocks_Poland\", output_dir)\n",
    "    \n",
    "    if len(tickers_30) > len(tickers_5):\n",
    "        run_analysis_for_subset(dfs_30, f\"{len(tickers_30)}_Stocks_Poland\", output_dir)\n",
    "    else:\n",
    "        print(\"Skipping large subset analysis (not enough stocks for distinct comparison).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd282ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a3835d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
