{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c34768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), \"../../\"))\n",
    "except NameError:\n",
    "    project_root = os.path.abspath(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fe0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beab53c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from utils.data.curating_stooq import curate_stooq_dir_5min\n",
    "from utils.data.jump_detection import detect_jumps_single, compute_u_shape\n",
    "from model.wavelet.wavelet import WaveletModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f6c74",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_pca_directions(X_windows, jumps_subset, output_dir, ticker):\n",
    "    \"\"\"\n",
    "    Visualizes what the PCA directions 'look like' by averaging x(t) profiles\n",
    "    for extreme quantiles along D1, D2, and D3.\n",
    "    \"\"\"\n",
    "    print(\"Generating PCA Direction visualizations (Average Profiles)...\")\n",
    "    \n",
    "    directions = [\"D1_reflexivity\", \"D2_mean_reversion\", \"D3_trend\"]\n",
    "    # For 5-min windows of length 25, center is at index 12\n",
    "    center = X_windows.shape[1] // 2\n",
    "    t_axis = np.arange(-center, center + 1)\n",
    "    \n",
    "    for dim in directions:\n",
    "        if dim not in jumps_subset.columns: continue\n",
    "        \n",
    "        # Create bins/quantiles\n",
    "        scores = jumps_subset[dim].values\n",
    "        # Define quantiles: Low (0-10%), Mid (45-55%), High (90-100%)\n",
    "        # Or 5 bins\n",
    "        quantiles = [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Sort X by score\n",
    "        sorted_indices = np.argsort(scores)\n",
    "        X_sorted = X_windows[sorted_indices]\n",
    "        \n",
    "        n = len(scores)\n",
    "        \n",
    "        # Plot average profile for each bin\n",
    "        colors = px.colors.sequential.Viridis\n",
    "        \n",
    "        for i in range(len(quantiles)-1):\n",
    "            q_start = quantiles[i]\n",
    "            q_end = quantiles[i+1]\n",
    "            \n",
    "            idx_start = int(q_start * n)\n",
    "            idx_end = int(q_end * n)\n",
    "            \n",
    "            if idx_end <= idx_start: continue\n",
    "            \n",
    "            # Average profile\n",
    "            avg_profile = np.mean(X_sorted[idx_start:idx_end], axis=0)\n",
    "            \n",
    "            # Color\n",
    "            color_idx = int(i / (len(quantiles)-1) * (len(colors)-1))\n",
    "            color = colors[color_idx]\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=t_axis,\n",
    "                y=avg_profile,\n",
    "                mode='lines',\n",
    "                name=f\"Q {q_start:.1f}-{q_end:.1f}\",\n",
    "                line=dict(color=color, width=2)\n",
    "            ))\n",
    "            \n",
    "        fig.update_layout(\n",
    "            title=f\"Average Jump Profiles along {dim} - {ticker}<br>Low Score (Purple) -> High Score (Yellow)\",\n",
    "            xaxis_title=\"Time Steps (Rel to Jump)\",\n",
    "            yaxis_title=\"Normalized Return x(t)\",\n",
    "            template=\"plotly_white\",\n",
    "            hovermode=\"x unified\"\n",
    "        )\n",
    "        \n",
    "        # Add Jump Marker line\n",
    "        fig.add_vline(x=0, line_dash=\"dash\", line_color=\"red\", annotation_text=\"Jump\")\n",
    "        \n",
    "        out_path = os.path.join(output_dir, f\"{ticker}_profile_{dim}.html\")\n",
    "        fig.write_html(out_path)\n",
    "        print(f\"  Saved profile for {dim} to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2cc3f7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ---------------------------------------------------------\n",
    "    # 1. Load Data for a Single Stock\n",
    "    # ---------------------------------------------------------\n",
    "    data_dir = \"/home/janis/4A/timeseries/data/stooq/hungary/\"\n",
    "    print(f\"Loading data from {data_dir}...\")\n",
    "    \n",
    "    # We load all to find the best one, or just pick the first valid one\n",
    "    # For efficiency, let's just find the largest file or load a few and pick best\n",
    "    dfs = curate_stooq_dir_5min(data_dir, pattern=\"*.txt\", recursive=True)\n",
    "    \n",
    "    if not dfs:\n",
    "        print(\"No data found.\")\n",
    "        return\n",
    "\n",
    "    # Pick the ticker with the most data points\n",
    "    ticker = max(dfs, key=lambda t: len(dfs[t]))\n",
    "    df = dfs[ticker]\n",
    "    print(f\"Selected Stock: {ticker} ({len(df)} 5-min bars)\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. Filter Trading Hours (10:30 - 15:00 approx)\n",
    "    # ---------------------------------------------------------\n",
    "    # Paper uses 10:30 - 15:00. \n",
    "    # Assuming standard day, we remove first 60 min and last 60 min.\n",
    "    print(\"Filtering trading hours (removing first/last 60 mins)...\")\n",
    "    \n",
    "    filtered_days = []\n",
    "    grouped = df.groupby(df.index.date)\n",
    "    for date, day_df in grouped:\n",
    "        if len(day_df) <= 12: continue # skip short days\n",
    "        day_df = day_df.sort_index()\n",
    "        start = day_df.index[0] + pd.Timedelta(minutes=60)\n",
    "        end = day_df.index[-1] - pd.Timedelta(minutes=60)\n",
    "        mask = (day_df.index >= start) & (day_df.index <= end)\n",
    "        filtered_days.append(day_df[mask])\n",
    "    \n",
    "    if not filtered_days:\n",
    "        print(\"No data left after filtering.\")\n",
    "        return\n",
    "        \n",
    "    df_filtered = pd.concat(filtered_days)\n",
    "    print(f\"Data points after filtering: {len(df_filtered)}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. Detect Jumps\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"Detecting jumps...\")\n",
    "    # We use the single version since we have one dataframe\n",
    "    jumps_df = detect_jumps_single(\n",
    "        df_filtered, \n",
    "        ticker=ticker, \n",
    "        threshold=4.0, \n",
    "        cluster_window=pd.Timedelta(\"1h\")\n",
    "    )\n",
    "    \n",
    "    print(f\"Detected {len(jumps_df)} jumps.\")\n",
    "    if len(jumps_df) < 5:\n",
    "        print(\"Not enough jumps to perform PCA analysis.\")\n",
    "        return\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4. Extract Jump Windows (x(t))\n",
    "    # ---------------------------------------------------------\n",
    "    # For 5-min data, we use window=12 (approx 60 mins)\n",
    "    window_steps = 12\n",
    "    windows = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    print(\"Extracting jump windows...\")\n",
    "    for idx, row in jumps_df.iterrows():\n",
    "        ts = row[\"timestamp\"]\n",
    "        if ts not in df_filtered.index: continue\n",
    "        \n",
    "        loc = df_filtered.index.get_loc(ts)\n",
    "        \n",
    "        # Check bounds\n",
    "        if loc - window_steps < 0 or loc + window_steps + 1 > len(df_filtered):\n",
    "            continue\n",
    "            \n",
    "        subset = df_filtered.iloc[loc - window_steps : loc + window_steps + 1]\n",
    "        \n",
    "        # Normalized return profile: r(t) / (f * sigma)\n",
    "        # We use the jump's stored f/sigma for normalization\n",
    "        norm = row[\"f\"] * row[\"sigma\"]\n",
    "        if norm == 0: norm = 1e-4\n",
    "            \n",
    "        # Compute returns for the window\n",
    "        # pct_change gives NaN at start, fill 0\n",
    "        r_window = subset[\"close\"].pct_change().fillna(0.0).values\n",
    "        \n",
    "        # Normalize\n",
    "        x_profile = r_window / norm\n",
    "        \n",
    "        # Align jump direction (center is at index `window_steps`)\n",
    "        # The paper aligns so that the jump itself is positive\n",
    "        jump_val = x_profile[window_steps]\n",
    "        jump_sign = np.sign(jump_val) if jump_val != 0 else 1\n",
    "        \n",
    "        windows.append(x_profile * jump_sign)\n",
    "        valid_indices.append(idx)\n",
    "\n",
    "    if not windows:\n",
    "        print(\"Could not extract any valid windows.\")\n",
    "        return\n",
    "        \n",
    "    X_windows = np.array(windows)\n",
    "    jumps_subset = jumps_df.loc[valid_indices].copy()\n",
    "    print(f\"Extracted {len(X_windows)} valid windows. Shape: {X_windows.shape}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 5. Wavelet Kernel PCA (D1: Reflexivity)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"Running Wavelet Kernel PCA...\")\n",
    "    # J=3 for ~25 length series\n",
    "    wm = WaveletModel(n_layers=0, n_neurons=0, n_outputs=0, J=3, n_components=3)\n",
    "    embedding = wm.fit_transform(X_windows)\n",
    "    \n",
    "    # Extract D1\n",
    "    d1 = embedding[:, 0]\n",
    "    \n",
    "    # Orient D1: Positive should correlate with Asymmetry (Activity After > Activity Before)\n",
    "    center = window_steps\n",
    "    # Activity After (t > 0)\n",
    "    act_post = np.sum(np.abs(X_windows[:, center+1:]), axis=1)\n",
    "    # Activity Before (t < 0)\n",
    "    act_pre = np.sum(np.abs(X_windows[:, :center]), axis=1)\n",
    "    \n",
    "    asymmetry = (act_post - act_pre) / (act_post + act_pre + 1e-6)\n",
    "    corr = np.corrcoef(d1, asymmetry)[0, 1]\n",
    "    \n",
    "    if corr < 0:\n",
    "        print(f\"Flipping D1 sign (correlation with asymmetry was {corr:.2f})\")\n",
    "        d1 *= -1\n",
    "    else:\n",
    "        print(f\"D1 sign is correct (correlation with asymmetry was {corr:.2f})\")\n",
    "        \n",
    "    jumps_subset[\"D1_reflexivity\"] = d1\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 6. Handcrafted Features (D2: Mean-Reversion, D3: Trend)\n",
    "    # ---------------------------------------------------------\n",
    "    # As per paper and our notebook refinement:\n",
    "    # D2 ~ Pre-Jump - Post-Jump (V-shape check)\n",
    "    # D3 ~ Pre-Jump + Post-Jump (Trend check)\n",
    "    # Using t = center-1 (pre) and t = center+1 (post)\n",
    "    \n",
    "    x_pre = X_windows[:, center - 1]\n",
    "    x_post = X_windows[:, center + 1]\n",
    "    \n",
    "    jumps_subset[\"D2_mean_reversion\"] = x_pre - x_post\n",
    "    jumps_subset[\"D3_trend\"] = x_pre + x_post\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 7. Reproduce Figures 5 & 6 (Plots)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"Generating plots...\")\n",
    "    \n",
    "    # Fig 5: Reflexivity vs Mean-Reversion\n",
    "    fig_mr = px.scatter(\n",
    "        jumps_subset,\n",
    "        x=\"D1_reflexivity\",\n",
    "        y=\"D2_mean_reversion\",\n",
    "        color=\"D2_mean_reversion\",\n",
    "        title=f\"<b>Reflexivity vs Mean-Reversion</b> ({ticker})<br>Reproduction of Paper Fig 5\",\n",
    "        labels={\n",
    "            \"D1_reflexivity\": \"Reflexivity (D1) [Endogenous <-> Exogenous]\",\n",
    "            \"D2_mean_reversion\": \"Mean Reversion (D2)\"\n",
    "        },\n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        opacity=0.7,\n",
    "        hover_data=[\"timestamp\", \"score\"]\n",
    "    )\n",
    "    fig_mr.add_vline(x=0, line_dash=\"dash\", line_color=\"gray\")\n",
    "    fig_mr.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\")\n",
    "    \n",
    "    # Fig 6: Reflexivity vs Trend\n",
    "    fig_tr = px.scatter(\n",
    "        jumps_subset,\n",
    "        x=\"D1_reflexivity\",\n",
    "        y=\"D3_trend\",\n",
    "        color=\"D3_trend\",\n",
    "        title=f\"<b>Reflexivity vs Trend</b> ({ticker})<br>Reproduction of Paper Fig 6\",\n",
    "        labels={\n",
    "            \"D1_reflexivity\": \"Reflexivity (D1) [Endogenous <-> Exogenous]\",\n",
    "            \"D3_trend\": \"Trend (D3)\"\n",
    "        },\n",
    "        color_continuous_scale=\"Viridis\",\n",
    "        opacity=0.7,\n",
    "        hover_data=[\"timestamp\", \"score\"]\n",
    "    )\n",
    "    fig_tr.add_vline(x=0, line_dash=\"dash\", line_color=\"gray\")\n",
    "    fig_tr.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\")\n",
    "\n",
    "    # Save or Show\n",
    "    # Since this is a script, we can show() but it might block or fail if headless.\n",
    "    # We'll try to write to HTML as well.\n",
    "    try:\n",
    "        base_dir = os.path.dirname(__file__)\n",
    "    except NameError:\n",
    "        base_dir = os.getcwd()\n",
    "\n",
    "    output_dir = os.path.join(base_dir, \"outputs\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    f_mr_path = os.path.join(output_dir, f\"{ticker}_fig5_mean_reversion.html\")\n",
    "    f_tr_path = os.path.join(output_dir, f\"{ticker}_fig6_trend.html\")\n",
    "    \n",
    "    fig_mr.write_html(f_mr_path)\n",
    "    fig_tr.write_html(f_tr_path)\n",
    "    \n",
    "    print(f\"Plots saved to:\\n  - {f_mr_path}\\n  - {f_tr_path}\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 8. Generate Profile Plots (Visualizing the Directions)\n",
    "    # ---------------------------------------------------------\n",
    "    plot_pca_directions(X_windows, jumps_subset, output_dir, ticker)\n",
    "    \n",
    "    # Optionally show if interactive\n",
    "    # fig_mr.show()\n",
    "    # fig_tr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c620f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
