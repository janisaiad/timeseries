{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f681c4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0f008e",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f3520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from math import log\n",
    "import IPython\n",
    "import geopandas\n",
    "import contextily as cx\n",
    "from math import asin, cos, radians, sin, sqrt\n",
    "\n",
    "\n",
    "from loadmydata.load_molene_meteo import load_molene_meteo_dataset\n",
    "from scipy.linalg import eigh\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ruptures as rpt\n",
    "from scipy.fft import fft\n",
    "from pygsp import graphs\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.signal import stft\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be001a20",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "The following cell loads the training data set `X_train` and `y_train`.\n",
    "`X_train` is a list of 100 signals; `y_train` is a list of 100 symbol sequences. \n",
    "\n",
    "The signals have a varying number of symbols with a varying duration. \n",
    "There is a brief silence between each symbol.\n",
    "The sampling frequency is $22.05 $ kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21df6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = 22050  # sampling frequency (Hz)\n",
    "\n",
    "X_train = np.load(\"X_train.npy\", allow_pickle=True).tolist()\n",
    "y_train = np.load(\"y_train.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e23b6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc6f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: STFT and energy computation\n",
    "# we compute the STFT to obtain the time-frequency representation\n",
    "# for each frequency bin, we compute the energy by integrating over the time axis\n",
    "\n",
    "signal = X_train[0]  # example signal\n",
    "window_length = 256\n",
    "overlap = window_length // 2\n",
    "\n",
    "# compute STFT\n",
    "f, t, Zxx = stft(signal, fs=FS, nperseg=window_length, noverlap=overlap)\n",
    "\n",
    "# compute energy for each frequency bin by integrating over time\n",
    "energy_per_freq = np.sum(np.abs(Zxx)**2, axis=1)  # shape: (n_freq,)\n",
    "\n",
    "print(f\"STFT shape: {Zxx.shape}\")\n",
    "print(f\"Energy per frequency shape: {energy_per_freq.shape}\")\n",
    "print(f\"Frequency bins: {len(f)}, Time frames: {len(t)}\")\n",
    "\n",
    "# visualization: STFT spectrogram and energy distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# plot 1: original signal\n",
    "axes[0, 0].plot(signal)\n",
    "axes[0, 0].set_title(\"Original Signal\")\n",
    "axes[0, 0].set_xlabel(\"Sample\")\n",
    "axes[0, 0].set_ylabel(\"Amplitude\")\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# plot 2: STFT spectrogram\n",
    "spectrogram = np.abs(Zxx)\n",
    "im1 = axes[0, 1].pcolormesh(t, f, 20 * np.log10(spectrogram + 1e-10), \n",
    "                            shading='gouraud', cmap='viridis')\n",
    "axes[0, 1].set_title(\"STFT Spectrogram\")\n",
    "axes[0, 1].set_xlabel(\"Time (s)\")\n",
    "axes[0, 1].set_ylabel(\"Frequency (Hz)\")\n",
    "axes[0, 1].set_ylim([0, 4000])  # focus on DTMF frequency range\n",
    "plt.colorbar(im1, ax=axes[0, 1], label=\"Magnitude (dB)\")\n",
    "\n",
    "# plot 3: energy per frequency bin\n",
    "axes[1, 0].plot(f, energy_per_freq, 'b-', linewidth=1.5)\n",
    "axes[1, 0].set_title(\"Energy per Frequency Bin\")\n",
    "axes[1, 0].set_xlabel(\"Frequency (Hz)\")\n",
    "axes[1, 0].set_ylabel(\"Energy\")\n",
    "axes[1, 0].set_xlim([0, 4000])\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# plot 4: energy per frequency (log scale)\n",
    "axes[1, 1].semilogy(f, energy_per_freq, 'b-', linewidth=1.5)\n",
    "axes[1, 1].set_title(\"Energy per Frequency Bin (Log Scale)\")\n",
    "axes[1, 1].set_xlabel(\"Frequency (Hz)\")\n",
    "axes[1, 1].set_ylabel(\"Energy (log scale)\")\n",
    "axes[1, 1].set_xlim([0, 4000])\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda9494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: First k-means (k=2) to separate signal from noise\n",
    "# we perform k-means clustering on the energy values to separate frequency bins \n",
    "# with high energy (signal) from those with low energy (noise)\n",
    "\n",
    "# reshape energy for k-means\n",
    "energy_reshaped = energy_per_freq.reshape(-1, 1)\n",
    "\n",
    "# k-means with k=2 to separate signal from noise\n",
    "kmeans_energy = KMeans(n_clusters=2, random_state=0, n_init=10)\n",
    "energy_labels = kmeans_energy.fit_predict(energy_reshaped)\n",
    "\n",
    "# identify which cluster has higher energy (signal cluster)\n",
    "cluster_centers = kmeans_energy.cluster_centers_.flatten()\n",
    "signal_cluster_idx = np.argmax(cluster_centers)\n",
    "noise_cluster_idx = 1 - signal_cluster_idx\n",
    "\n",
    "# get frequency bins that belong to signal cluster\n",
    "high_energy_freq_indices = np.where(energy_labels == signal_cluster_idx)[0]\n",
    "high_energy_freqs = f[high_energy_freq_indices]\n",
    "\n",
    "print(f\"Total frequency bins: {len(f)}\")\n",
    "print(f\"High-energy (signal) bins: {len(high_energy_freq_indices)}\")\n",
    "print(f\"Noise bins: {len(f) - len(high_energy_freq_indices)}\")\n",
    "print(f\"Signal cluster center energy: {cluster_centers[signal_cluster_idx]:.2e}\")\n",
    "print(f\"Noise cluster center energy: {cluster_centers[noise_cluster_idx]:.2e}\")\n",
    "\n",
    "# visualization: energy clustering results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# plot 1: energy distribution with cluster assignment\n",
    "colors = ['red' if label == signal_cluster_idx else 'gray' \n",
    "          for label in energy_labels]\n",
    "axes[0, 0].scatter(f, energy_per_freq, c=colors, alpha=0.6, s=30)\n",
    "axes[0, 0].axhline(y=cluster_centers[signal_cluster_idx], \n",
    "                   color='red', linestyle='--', linewidth=2, label='Signal cluster center')\n",
    "axes[0, 0].axhline(y=cluster_centers[noise_cluster_idx], \n",
    "                   color='gray', linestyle='--', linewidth=2, label='Noise cluster center')\n",
    "axes[0, 0].set_title(\"Energy Clustering (k=2): Signal vs Noise\")\n",
    "axes[0, 0].set_xlabel(\"Frequency (Hz)\")\n",
    "axes[0, 0].set_ylabel(\"Energy\")\n",
    "axes[0, 0].set_xlim([0, 4000])\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# plot 2: energy distribution (log scale) with clusters\n",
    "axes[0, 1].semilogy(f[energy_labels == signal_cluster_idx], \n",
    "                    energy_per_freq[energy_labels == signal_cluster_idx], \n",
    "                    'ro', markersize=8, alpha=0.7, label='Signal bins')\n",
    "axes[0, 1].semilogy(f[energy_labels == noise_cluster_idx], \n",
    "                    energy_per_freq[energy_labels == noise_cluster_idx], \n",
    "                    'ko', markersize=4, alpha=0.5, label='Noise bins')\n",
    "axes[0, 1].axhline(y=cluster_centers[signal_cluster_idx], \n",
    "                   color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 1].axhline(y=cluster_centers[noise_cluster_idx], \n",
    "                   color='gray', linestyle='--', linewidth=2)\n",
    "axes[0, 1].set_title(\"Energy Clustering (Log Scale)\")\n",
    "axes[0, 1].set_xlabel(\"Frequency (Hz)\")\n",
    "axes[0, 1].set_ylabel(\"Energy (log scale)\")\n",
    "axes[0, 1].set_xlim([0, 4000])\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# plot 3: histogram of energy values with cluster centers\n",
    "axes[1, 0].hist(energy_per_freq[energy_labels == noise_cluster_idx], \n",
    "                bins=50, alpha=0.6, color='gray', label='Noise bins')\n",
    "axes[1, 0].hist(energy_per_freq[energy_labels == signal_cluster_idx], \n",
    "                bins=50, alpha=0.6, color='red', label='Signal bins')\n",
    "axes[1, 0].axvline(x=cluster_centers[signal_cluster_idx], \n",
    "                   color='red', linestyle='--', linewidth=2, label='Signal center')\n",
    "axes[1, 0].axvline(x=cluster_centers[noise_cluster_idx], \n",
    "                   color='gray', linestyle='--', linewidth=2, label='Noise center')\n",
    "axes[1, 0].set_title(\"Energy Distribution Histogram\")\n",
    "axes[1, 0].set_xlabel(\"Energy\")\n",
    "axes[1, 0].set_ylabel(\"Count\")\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# plot 4: spectrogram highlighting signal vs noise bins\n",
    "spectrogram = np.abs(Zxx)\n",
    "im = axes[1, 1].pcolormesh(t, f, 20 * np.log10(spectrogram + 1e-10), \n",
    "                           shading='gouraud', cmap='gray')\n",
    "# highlight signal bins\n",
    "for idx in high_energy_freq_indices:\n",
    "    axes[1, 1].axhline(y=f[idx], color='red', linewidth=1, alpha=0.5)\n",
    "axes[1, 1].set_title(\"Spectrogram with Signal Bins Highlighted (Red)\")\n",
    "axes[1, 1].set_xlabel(\"Time (s)\")\n",
    "axes[1, 1].set_ylabel(\"Frequency (Hz)\")\n",
    "axes[1, 1].set_ylim([0, 4000])\n",
    "plt.colorbar(im, ax=axes[1, 1], label=\"Magnitude (dB)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bb8e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Second k-means (k=8) to group frequency bins into DTMF frequency bands\n",
    "# within the high-energy frequency bins, multiple bins may correspond to the same \n",
    "# DTMF frequency due to spectral leakage. we perform 2D k-means clustering \n",
    "# on the (frequency, energy) plane to group them into the major DTMF frequency bands\n",
    "\n",
    "# get frequency and energy values of high-energy bins for 2D clustering\n",
    "high_energy_freqs = f[high_energy_freq_indices]\n",
    "high_energy_energies = energy_per_freq[high_energy_freq_indices]\n",
    "\n",
    "# normalize features for clustering (frequency and energy on different scales)\n",
    "freq_normalized = (high_energy_freqs - high_energy_freqs.min()) / (high_energy_freqs.max() - high_energy_freqs.min() + 1e-10)\n",
    "energy_normalized = (high_energy_energies - high_energy_energies.min()) / (high_energy_energies.max() - high_energy_energies.min() + 1e-10)\n",
    "\n",
    "# 2D feature matrix: (frequency, energy)\n",
    "features_2d = np.column_stack([freq_normalized, energy_normalized])\n",
    "\n",
    "# k-means with k=8 to group into DTMF frequency bands (4 low + 4 high)\n",
    "kmeans_freq = KMeans(n_clusters=8, random_state=0, n_init=10)\n",
    "freq_cluster_labels = kmeans_freq.fit_predict(features_2d)\n",
    "\n",
    "# get the 8 major frequency clusters\n",
    "major_freq_clusters = []\n",
    "for cluster_id in range(8):\n",
    "    cluster_mask = freq_cluster_labels == cluster_id\n",
    "    cluster_freq_indices = high_energy_freq_indices[cluster_mask]\n",
    "    cluster_freqs = high_energy_freqs[cluster_mask]\n",
    "    cluster_energies = high_energy_energies[cluster_mask]\n",
    "    \n",
    "    # compute cluster center in original space\n",
    "    cluster_center_freq = np.mean(cluster_freqs)\n",
    "    cluster_center_energy = np.mean(cluster_energies)\n",
    "    \n",
    "    major_freq_clusters.append({\n",
    "        'cluster_id': cluster_id,\n",
    "        'center_freq': cluster_center_freq,\n",
    "        'center_energy': cluster_center_energy,\n",
    "        'freq_indices': cluster_freq_indices,\n",
    "        'freqs': cluster_freqs,\n",
    "        'energies': cluster_energies\n",
    "    })\n",
    "\n",
    "# filter out clusters with only 1 frequency bin\n",
    "major_freq_clusters = [c for c in major_freq_clusters if len(c['freq_indices']) > 1]\n",
    "\n",
    "# filter out outlier clusters (frequencies outside typical DTMF range: 600-1700 Hz)\n",
    "# DTMF frequencies: low group ~697, 770, 852, 941 Hz; high group ~1209, 1336, 1477, 1633 Hz\n",
    "dtmf_freq_range = (500, 1800)  # allow some margin\n",
    "major_freq_clusters = [c for c in major_freq_clusters \n",
    "                      if dtmf_freq_range[0] <= c['center_freq'] <= dtmf_freq_range[1]]\n",
    "\n",
    "# sort by center frequency\n",
    "major_freq_clusters.sort(key=lambda x: x['center_freq'])\n",
    "\n",
    "print(f\"Number of major frequency clusters (after filtering): {len(major_freq_clusters)}\")\n",
    "for i, cluster in enumerate(major_freq_clusters):\n",
    "    print(f\"Cluster {i}: center={cluster['center_freq']:.1f} Hz, \"\n",
    "          f\"energy={cluster['center_energy']:.2e}, n_bins={len(cluster['freq_indices'])}\")\n",
    "\n",
    "# visualization: 2D clustering in energy-frequency plane\n",
    "n_clusters = len(major_freq_clusters)\n",
    "colors_clusters = plt.cm.tab10(np.linspace(0, 1, n_clusters))\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# plot 1: 2D clustering in energy-frequency plane (main visualization)\n",
    "for i, cluster in enumerate(major_freq_clusters):\n",
    "    axes[0, 0].scatter(cluster['freqs'], cluster['energies'], \n",
    "                      c=[colors_clusters[i]], s=150, alpha=0.7, \n",
    "                      edgecolors='black', linewidths=1.5,\n",
    "                      label=f\"Cluster {i}: {cluster['center_freq']:.0f} Hz\")\n",
    "    # plot cluster center\n",
    "    axes[0, 0].plot(cluster['center_freq'], cluster['center_energy'], \n",
    "                   'x', color=colors_clusters[i], markersize=15, \n",
    "                   markeredgewidth=3, label=f\"Center {i}\" if i == 0 else \"\")\n",
    "axes[0, 0].set_title(\"2D Clustering in Energy-Frequency Plane\", fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel(\"Frequency (Hz)\")\n",
    "axes[0, 0].set_ylabel(\"Energy\")\n",
    "axes[0, 0].set_xlim([0, 4000])\n",
    "axes[0, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# plot 2: 2D clustering on log scale\n",
    "for i, cluster in enumerate(major_freq_clusters):\n",
    "    axes[0, 1].semilogy(cluster['freqs'], cluster['energies'], \n",
    "                       'o', color=colors_clusters[i], markersize=12, \n",
    "                       alpha=0.7, markeredgecolor='black', markeredgewidth=1.5,\n",
    "                       label=f\"Cluster {i}: {cluster['center_freq']:.0f} Hz\")\n",
    "    axes[0, 1].semilogy(cluster['center_freq'], cluster['center_energy'], \n",
    "                       'x', color=colors_clusters[i], markersize=15, \n",
    "                       markeredgewidth=3)\n",
    "axes[0, 1].set_title(\"2D Clustering (Log Energy Scale)\", fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel(\"Frequency (Hz)\")\n",
    "axes[0, 1].set_ylabel(\"Energy (log scale)\")\n",
    "axes[0, 1].set_xlim([0, 4000])\n",
    "axes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# plot 3: spectrogram with filtered frequency clusters highlighted\n",
    "spectrogram = np.abs(Zxx)\n",
    "im = axes[1, 0].pcolormesh(t, f, 20 * np.log10(spectrogram + 1e-10), \n",
    "                           shading='gouraud', cmap='gray')\n",
    "for i, cluster in enumerate(major_freq_clusters):\n",
    "    for idx in cluster['freq_indices']:\n",
    "        axes[1, 0].axhline(y=f[idx], color=colors_clusters[i], \n",
    "                          linewidth=2.5, alpha=0.8, \n",
    "                          label=f\"Cluster {i}\" if idx == cluster['freq_indices'][0] else \"\")\n",
    "axes[1, 0].set_title(f\"Spectrogram with {n_clusters} Frequency Clusters\", \n",
    "                    fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel(\"Time (s)\")\n",
    "axes[1, 0].set_ylabel(\"Frequency (Hz)\")\n",
    "axes[1, 0].set_ylim([0, 4000])\n",
    "plt.colorbar(im, ax=axes[1, 0], label=\"Magnitude (dB)\")\n",
    "\n",
    "# plot 4: cluster centers and bin distribution (bar chart)\n",
    "if n_clusters > 0:\n",
    "    cluster_centers_freq = [c['center_freq'] for c in major_freq_clusters]\n",
    "    cluster_sizes = [len(c['freq_indices']) for c in major_freq_clusters]\n",
    "    bars = axes[1, 1].bar(range(n_clusters), cluster_centers_freq, \n",
    "                         color=colors_clusters[:n_clusters], alpha=0.7, \n",
    "                         edgecolor='black', linewidth=1.5)\n",
    "    axes[1, 1].set_title(f\"{n_clusters} DTMF Frequency Cluster Centers\", \n",
    "                        fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel(\"Cluster Index\")\n",
    "    axes[1, 1].set_ylabel(\"Center Frequency (Hz)\")\n",
    "    axes[1, 1].set_xticks(range(n_clusters))\n",
    "    axes[1, 1].set_xticklabels([f\"{c['center_freq']:.0f}Hz\" \n",
    "                               for c in major_freq_clusters], \n",
    "                               rotation=45, ha='right')\n",
    "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "    # add size labels on bars\n",
    "    for i, (bar, size) in enumerate(zip(bars, cluster_sizes)):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{size} bins', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# additional visualization: 2D clustering with Voronoi-like regions\n",
    "fig2, ax2 = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "# plot all high-energy points colored by cluster\n",
    "for i, cluster in enumerate(major_freq_clusters):\n",
    "    ax2.scatter(cluster['freqs'], cluster['energies'], \n",
    "               c=[colors_clusters[i]], s=200, alpha=0.6, \n",
    "               edgecolors='black', linewidths=2,\n",
    "               label=f\"Cluster {i}: {cluster['center_freq']:.0f} Hz ({len(cluster['freq_indices'])} bins)\")\n",
    "    # plot cluster center\n",
    "    ax2.plot(cluster['center_freq'], cluster['center_energy'], \n",
    "            'x', color=colors_clusters[i], markersize=20, \n",
    "            markeredgewidth=4, label=f\"Center {i}\" if i == 0 else \"\")\n",
    "\n",
    "# plot noise bins in gray\n",
    "noise_freq_indices = np.setdiff1d(np.arange(len(f)), high_energy_freq_indices)\n",
    "noise_freqs = f[noise_freq_indices]\n",
    "noise_energies = energy_per_freq[noise_freq_indices]\n",
    "ax2.scatter(noise_freqs, noise_energies, c='lightgray', s=30, \n",
    "           alpha=0.3, label='Noise bins', edgecolors='none')\n",
    "\n",
    "ax2.set_title(\"2D Clustering: Energy-Frequency Plane\\n(Filtered Clusters Only)\", \n",
    "             fontsize=16, fontweight='bold')\n",
    "ax2.set_xlabel(\"Frequency (Hz)\", fontsize=12)\n",
    "ax2.set_ylabel(\"Energy\", fontsize=12)\n",
    "ax2.set_xlim([0, 4000])\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85db03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Changepoint detection on each frequency cluster\n",
    "# for each cluster, we perform CP on each frequency bin separately\n",
    "# since DTMF is dual-tone, we choose the frequency that gives the minimum number of CP points\n",
    "# (the more stable/clear frequency determines the changepoints)\n",
    "\n",
    "# compute energy signal for each frequency cluster over time\n",
    "t_max = len(t)\n",
    "all_changepoints = []\n",
    "cluster_energy_signals = []  # store for visualization\n",
    "frame_step = window_length - overlap\n",
    "\n",
    "for cluster in major_freq_clusters:\n",
    "    freq_indices = cluster['freq_indices']\n",
    "    n_freqs = len(freq_indices)\n",
    "    \n",
    "    # perform CP on each frequency bin separately\n",
    "    freq_cp_results = []\n",
    "    \n",
    "    for freq_idx in freq_indices:\n",
    "        # get energy signal for this single frequency bin\n",
    "        freq_energy = np.abs(Zxx[freq_idx, :])**2\n",
    "        \n",
    "        # apply changepoint detection using PELT\n",
    "        # BIC penalty: beta = 2 * sigma^2 * log(T)\n",
    "        sigma_est = np.std(freq_energy)\n",
    "        pen_bic = 2 * sigma_est**2 * np.log(t_max)\n",
    "        \n",
    "        # PELT algorithm\n",
    "        algo = rpt.Pelt(model=\"l2\", jump=1)\n",
    "        predicted_bkps = algo.fit_predict(freq_energy, pen=pen_bic)\n",
    "        \n",
    "        # convert frame indices to sample indices\n",
    "        signal_bkps = [min(int(idx * frame_step), len(signal)) \n",
    "                       for idx in predicted_bkps[:-1]]\n",
    "        \n",
    "        freq_cp_results.append({\n",
    "            'freq_idx': freq_idx,\n",
    "            'freq_value': f[freq_idx],\n",
    "            'changepoints': signal_bkps,\n",
    "            'frame_bkps': predicted_bkps[:-1],\n",
    "            'n_cps': len(signal_bkps),\n",
    "            'energy_signal': freq_energy\n",
    "        })\n",
    "    \n",
    "    # choose the frequency with minimum number of CP points (most stable for dual-tone)\n",
    "    best_freq_result = min(freq_cp_results, key=lambda x: x['n_cps'])\n",
    "    \n",
    "    # also store all frequency results for visualization\n",
    "    all_freq_results = freq_cp_results.copy()\n",
    "    \n",
    "    all_changepoints.append({\n",
    "        'cluster_id': cluster['cluster_id'],\n",
    "        'center_freq': cluster['center_freq'],\n",
    "        'selected_freq': best_freq_result['freq_value'],\n",
    "        'selected_freq_idx': best_freq_result['freq_idx'],\n",
    "        'changepoints': best_freq_result['changepoints'],\n",
    "        'frame_bkps': best_freq_result['frame_bkps'],\n",
    "        'energy_signal': best_freq_result['energy_signal'],\n",
    "        'n_cps': best_freq_result['n_cps'],\n",
    "        'all_freq_results': all_freq_results  # store all for comparison\n",
    "    })\n",
    "    \n",
    "    print(f\"Cluster {cluster['cluster_id']} (center={cluster['center_freq']:.1f} Hz, {n_freqs} freqs):\")\n",
    "    print(f\"  Selected freq: {best_freq_result['freq_value']:.1f} Hz with {best_freq_result['n_cps']} CPs\")\n",
    "    for fr in freq_cp_results:\n",
    "        marker = \" <-- selected\" if fr['freq_idx'] == best_freq_result['freq_idx'] else \"\"\n",
    "        print(f\"    Freq {fr['freq_value']:.1f} Hz: {fr['n_cps']} CPs{marker}\")\n",
    "\n",
    "# combine changepoints from all clusters\n",
    "all_bkps = sorted(set([bp for cp_dict in all_changepoints \n",
    "                       for bp in cp_dict['changepoints']]))\n",
    "print(f\"\\nTotal unique changepoints across all clusters: {len(all_bkps)}\")\n",
    "print(f\"Changepoint positions: {all_bkps[:10]}...\")  # show first 10\n",
    "\n",
    "# visualization: changepoint detection results\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(4, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# plot 1: original signal with all changepoints\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.plot(signal, 'b-', linewidth=0.8, alpha=0.7, label='Signal')\n",
    "for bp in all_bkps:\n",
    "    ax1.axvline(x=bp, color='red', linestyle='--', linewidth=1.5, alpha=0.6)\n",
    "ax1.set_title(\"Original Signal with Detected Changepoints\", fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel(\"Sample\")\n",
    "ax1.set_ylabel(\"Amplitude\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# plot 2-5: energy signals with changepoints for first 4 clusters\n",
    "# show all frequencies in each cluster, highlighting the selected one\n",
    "colors_8 = plt.cm.tab10(np.linspace(0, 1, 8))\n",
    "for idx in range(min(4, len(all_changepoints))):\n",
    "    cp_dict = all_changepoints[idx]\n",
    "    ax = fig.add_subplot(gs[1 + idx//2, idx%2])\n",
    "    \n",
    "    # plot all frequencies in this cluster (faded)\n",
    "    for fr_result in cp_dict['all_freq_results']:\n",
    "        if fr_result['freq_idx'] != cp_dict['selected_freq_idx']:\n",
    "            ax.plot(t, fr_result['energy_signal'], \n",
    "                   color=colors_8[cp_dict['cluster_id']], linewidth=1, \n",
    "                   alpha=0.3, linestyle='--',\n",
    "                   label=f\"f={fr_result['freq_value']:.0f} Hz ({fr_result['n_cps']} CPs)\")\n",
    "    \n",
    "    # plot selected frequency (bold)\n",
    "    ax.plot(t, cp_dict['energy_signal'], \n",
    "           color=colors_8[cp_dict['cluster_id']], linewidth=2.5, \n",
    "           label=f\"SELECTED: f={cp_dict['selected_freq']:.0f} Hz ({cp_dict['n_cps']} CPs)\")\n",
    "    \n",
    "    # plot changepoints for selected frequency\n",
    "    for frame_bp in cp_dict['frame_bkps']:\n",
    "        if frame_bp < len(t):\n",
    "            ax.axvline(x=t[frame_bp], color='red', \n",
    "                      linestyle='--', linewidth=2, alpha=0.8)\n",
    "    \n",
    "    ax.set_title(f\"Cluster {cp_dict['cluster_id']}: Frequency Comparison\\n\"\n",
    "                f\"(Center: {cp_dict['center_freq']:.0f} Hz, Selected: {cp_dict['selected_freq']:.0f} Hz)\",\n",
    "                fontweight='bold')\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Energy\")\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# plot 6: spectrogram with changepoints overlaid\n",
    "ax6 = fig.add_subplot(gs[3, 0])\n",
    "spectrogram = np.abs(Zxx)\n",
    "im = ax6.pcolormesh(t, f, 20 * np.log10(spectrogram + 1e-10), \n",
    "                   shading='gouraud', cmap='viridis')\n",
    "# overlay changepoints as vertical lines\n",
    "for cp_dict in all_changepoints:\n",
    "    for frame_bp in cp_dict['frame_bkps']:\n",
    "        if frame_bp < len(t):\n",
    "            ax6.axvline(x=t[frame_bp], color='red', \n",
    "                       linestyle='--', linewidth=1.5, alpha=0.6)\n",
    "ax6.set_title(\"Spectrogram with Changepoints\")\n",
    "ax6.set_xlabel(\"Time (s)\")\n",
    "ax6.set_ylabel(\"Frequency (Hz)\")\n",
    "ax6.set_ylim([0, 4000])\n",
    "plt.colorbar(im, ax=ax6, label=\"Magnitude (dB)\")\n",
    "\n",
    "# plot 7: changepoint frequency across clusters with selected frequencies\n",
    "ax7 = fig.add_subplot(gs[3, 1])\n",
    "cluster_ids = [cp['cluster_id'] for cp in all_changepoints]\n",
    "n_changepoints = [cp['n_cps'] for cp in all_changepoints]\n",
    "selected_freqs = [cp['selected_freq'] for cp in all_changepoints]\n",
    "bars = ax7.bar(range(len(all_changepoints)), n_changepoints, \n",
    "              color=[colors_8[i] for i in cluster_ids], alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax7.set_title(\"Number of Changepoints per Cluster\\n(Selected Frequency Shown)\", \n",
    "             fontweight='bold')\n",
    "ax7.set_xlabel(\"Cluster Index\")\n",
    "ax7.set_ylabel(\"Number of Changepoints\")\n",
    "ax7.set_xticks(range(len(all_changepoints)))\n",
    "ax7.set_xticklabels([f\"{cp['center_freq']:.0f}Hz\\n→{cp['selected_freq']:.0f}Hz\" \n",
    "                    for cp in all_changepoints], \n",
    "                    rotation=45, ha='right', fontsize=8)\n",
    "ax7.grid(True, alpha=0.3, axis='y')\n",
    "# add value labels on bars\n",
    "for bar, n_cp, sel_freq in zip(bars, n_changepoints, selected_freqs):\n",
    "    height = bar.get_height()\n",
    "    ax7.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{n_cp} CPs', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# additional detailed visualization: frequency comparison for all clusters\n",
    "n_clusters = len(all_changepoints)\n",
    "n_rows = (n_clusters + 1) // 2\n",
    "fig2, axes2 = plt.subplots(n_rows, 2, figsize=(16, 4*n_rows))\n",
    "if n_rows == 1:\n",
    "    axes2 = axes2.reshape(1, -1)\n",
    "axes2 = axes2.flatten()\n",
    "\n",
    "for idx, cp_dict in enumerate(all_changepoints):\n",
    "    ax = axes2[idx]\n",
    "    \n",
    "    # plot all frequencies in this cluster (faded)\n",
    "    for fr_result in cp_dict['all_freq_results']:\n",
    "        if fr_result['freq_idx'] != cp_dict['selected_freq_idx']:\n",
    "            ax.plot(t, fr_result['energy_signal'], \n",
    "                   color=colors_8[cp_dict['cluster_id']], linewidth=1, \n",
    "                   alpha=0.25, linestyle='--')\n",
    "    \n",
    "    # plot selected frequency (bold)\n",
    "    ax.plot(t, cp_dict['energy_signal'], \n",
    "           color=colors_8[cp_dict['cluster_id']], linewidth=2.5)\n",
    "    \n",
    "    # mark changepoints for selected frequency\n",
    "    for frame_bp in cp_dict['frame_bkps']:\n",
    "        if frame_bp < len(t):\n",
    "            ax.axvline(x=t[frame_bp], color='red', \n",
    "                      linestyle='--', linewidth=2, alpha=0.8)\n",
    "            ax.plot(t[frame_bp], cp_dict['energy_signal'][frame_bp], \n",
    "                   'ro', markersize=8)\n",
    "    \n",
    "    # add text annotation showing frequency comparison\n",
    "    freq_info = \", \".join([f\"{fr['freq_value']:.0f}Hz({fr['n_cps']}CPs)\" \n",
    "                          for fr in cp_dict['all_freq_results']])\n",
    "    selected_marker = f\"→ {cp_dict['selected_freq']:.0f}Hz selected\"\n",
    "    \n",
    "    ax.set_title(f\"Cluster {cp_dict['cluster_id']}: {cp_dict['center_freq']:.0f} Hz center\\n\"\n",
    "                f\"Freqs: {freq_info} | {selected_marker}\", \n",
    "                fontsize=9, fontweight='bold')\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Energy\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# hide unused subplots\n",
    "for idx in range(n_clusters, len(axes2)):\n",
    "    axes2[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe50bb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Cell 5: Order changepoints and assign DTMF symbols\n",
    "# since DTMF uses dual-tone (low + high frequency), we need to:\n",
    "# 1. group clusters into low and high frequency groups\n",
    "# 2. order all changepoints chronologically\n",
    "# 3. for each time segment, determine which low+high frequency pair is active\n",
    "# 4. map frequency pairs to DTMF symbols (4x4 = 16 possible symbols)\n",
    "\n",
    "# DTMF frequency standards\n",
    "dtmf_low_freqs = [697, 770, 852, 941]  # Hz\n",
    "dtmf_high_freqs = [1209, 1336, 1477, 1633]  # Hz\n",
    "\n",
    "# DTMF symbol mapping (row x column)\n",
    "dtmf_symbols = [\n",
    "    ['1', '2', '3', 'A'],  # row 0: 697 Hz\n",
    "    ['4', '5', '6', 'B'],  # row 1: 770 Hz\n",
    "    ['7', '8', '9', 'C'],  # row 2: 852 Hz\n",
    "    ['*', '0', '#', 'D']   # row 3: 941 Hz\n",
    "]\n",
    "\n",
    "# group clusters into low and high frequency groups\n",
    "low_freq_clusters = []\n",
    "high_freq_clusters = []\n",
    "freq_threshold = 1000  # threshold between low and high groups\n",
    "\n",
    "for cp_dict in all_changepoints:\n",
    "    if cp_dict['selected_freq'] < freq_threshold:\n",
    "        low_freq_clusters.append(cp_dict)\n",
    "    else:\n",
    "        high_freq_clusters.append(cp_dict)\n",
    "\n",
    "print(f\"Low frequency clusters: {len(low_freq_clusters)}\")\n",
    "for c in low_freq_clusters:\n",
    "    print(f\"  {c['selected_freq']:.1f} Hz (cluster {c['cluster_id']})\")\n",
    "print(f\"\\nHigh frequency clusters: {len(high_freq_clusters)}\")\n",
    "for c in high_freq_clusters:\n",
    "    print(f\"  {c['selected_freq']:.1f} Hz (cluster {c['cluster_id']})\")\n",
    "\n",
    "# collect all changepoints and order them chronologically\n",
    "all_cp_times = []  # store as (time_sample, cluster_id, freq_type)\n",
    "for cp_dict in all_changepoints:\n",
    "    freq_type = 'low' if cp_dict['selected_freq'] < freq_threshold else 'high'\n",
    "    for cp_sample in cp_dict['changepoints']:\n",
    "        all_cp_times.append((cp_sample, cp_dict['cluster_id'], freq_type, cp_dict['selected_freq']))\n",
    "\n",
    "# sort by time\n",
    "all_cp_times.sort(key=lambda x: x[0])\n",
    "\n",
    "# add start and end boundaries\n",
    "all_cp_times = [(0, None, 'start', None)] + all_cp_times + [(len(signal), None, 'end', None)]\n",
    "\n",
    "print(f\"\\nTotal changepoints (ordered): {len(all_cp_times) - 2}\")  # exclude start/end\n",
    "print(f\"Changepoint times: {[cp[0] for cp in all_cp_times[1:min(11, len(all_cp_times)-1)]]}...\")\n",
    "\n",
    "# function to map frequency to DTMF index\n",
    "def freq_to_dtmf_index(freq, freq_list):\n",
    "    \"\"\"find closest DTMF frequency and return its index\"\"\"\n",
    "    distances = [abs(freq - dtmf_f) for dtmf_f in freq_list]\n",
    "    min_idx = np.argmin(distances)\n",
    "    min_dist = distances[min_idx]\n",
    "    # only match if within reasonable tolerance (50 Hz)\n",
    "    if min_dist < 50:\n",
    "        return min_idx\n",
    "    return None\n",
    "\n",
    "# function to check if a frequency is active in a time segment\n",
    "def is_freq_active_in_segment(freq_clusters, start_time, end_time, frame_step, energy_threshold_ratio=0.3):\n",
    "    \"\"\"check if frequency energy is above threshold in this segment\"\"\"\n",
    "    active_freqs = []\n",
    "    for cp_dict in freq_clusters:\n",
    "        # convert sample times to frame indices\n",
    "        start_frame = max(0, int(start_time / frame_step))\n",
    "        end_frame = min(len(cp_dict['energy_signal']), int(end_time / frame_step) + 1)\n",
    "        \n",
    "        if start_frame >= end_frame:\n",
    "            continue\n",
    "            \n",
    "        # get energy signal for this segment\n",
    "        segment_energy = cp_dict['energy_signal'][start_frame:end_frame]\n",
    "        \n",
    "        if len(segment_energy) == 0:\n",
    "            continue\n",
    "        \n",
    "        # check if average energy is above threshold (relative to max energy of this frequency)\n",
    "        max_energy = np.max(cp_dict['energy_signal'])\n",
    "        avg_energy = np.mean(segment_energy)\n",
    "        \n",
    "        # frequency is active if average energy is above threshold\n",
    "        if avg_energy > energy_threshold_ratio * max_energy:\n",
    "            active_freqs.append({\n",
    "                'freq': cp_dict['selected_freq'],\n",
    "                'avg_energy': avg_energy,\n",
    "                'max_energy': max_energy\n",
    "            })\n",
    "    \n",
    "    # sort by energy (strongest first) and return frequencies\n",
    "    active_freqs.sort(key=lambda x: x['avg_energy'], reverse=True)\n",
    "    return [f['freq'] for f in active_freqs]\n",
    "\n",
    "# detect symbols for each time segment\n",
    "detected_symbols = []\n",
    "for i in range(len(all_cp_times) - 1):\n",
    "    start_time = all_cp_times[i][0]\n",
    "    end_time = all_cp_times[i+1][0]\n",
    "    segment_duration = end_time - start_time\n",
    "    \n",
    "    # skip very short segments (likely noise)\n",
    "    if segment_duration < 100:  # minimum duration threshold\n",
    "        continue\n",
    "    \n",
    "    # find active frequencies in this segment (check energy levels)\n",
    "    active_low_freqs = is_freq_active_in_segment(low_freq_clusters, start_time, end_time, frame_step)\n",
    "    active_high_freqs = is_freq_active_in_segment(high_freq_clusters, start_time, end_time, frame_step)\n",
    "    \n",
    "    # if we have both low and high frequencies, assign symbol\n",
    "    if len(active_low_freqs) > 0 and len(active_high_freqs) > 0:\n",
    "        # use the most common or first frequency in each group\n",
    "        low_freq = active_low_freqs[0]  # take first active\n",
    "        high_freq = active_high_freqs[0]\n",
    "        \n",
    "        # map to DTMF indices\n",
    "        low_idx = freq_to_dtmf_index(low_freq, dtmf_low_freqs)\n",
    "        high_idx = freq_to_dtmf_index(high_freq, dtmf_high_freqs)\n",
    "        \n",
    "        if low_idx is not None and high_idx is not None:\n",
    "            symbol = dtmf_symbols[low_idx][high_idx]\n",
    "            detected_symbols.append({\n",
    "                'symbol': symbol,\n",
    "                'start_time': start_time,\n",
    "                'end_time': end_time,\n",
    "                'duration': segment_duration,\n",
    "                'low_freq': low_freq,\n",
    "                'high_freq': high_freq,\n",
    "                'low_idx': low_idx,\n",
    "                'high_idx': high_idx\n",
    "            })\n",
    "        else:\n",
    "            # unmatched frequencies\n",
    "            detected_symbols.append({\n",
    "                'symbol': '?',\n",
    "                'start_time': start_time,\n",
    "                'end_time': end_time,\n",
    "                'duration': segment_duration,\n",
    "                'low_freq': low_freq,\n",
    "                'high_freq': high_freq,\n",
    "                'low_idx': None,\n",
    "                'high_idx': None\n",
    "            })\n",
    "    elif len(active_low_freqs) > 0 or len(active_high_freqs) > 0:\n",
    "        # only one frequency group active (silence or partial)\n",
    "        detected_symbols.append({\n",
    "            'symbol': '_',  # silence or partial\n",
    "            'start_time': start_time,\n",
    "            'end_time': end_time,\n",
    "            'duration': segment_duration,\n",
    "            'low_freq': active_low_freqs[0] if active_low_freqs else None,\n",
    "            'high_freq': active_high_freqs[0] if active_high_freqs else None,\n",
    "            'low_idx': None,\n",
    "            'high_idx': None\n",
    "        })\n",
    "\n",
    "# print detected symbols\n",
    "print(f\"\\n=== Detected DTMF Symbols ===\")\n",
    "symbol_sequence = ''.join([s['symbol'] for s in detected_symbols])\n",
    "print(f\"Symbol sequence: {symbol_sequence}\")\n",
    "print(f\"\\nDetailed breakdown:\")\n",
    "for i, sym in enumerate(detected_symbols):\n",
    "    if sym['symbol'] not in ['_', '?']:\n",
    "        print(f\"  {i+1}. '{sym['symbol']}' at t=[{sym['start_time']/FS:.3f}, {sym['end_time']/FS:.3f}]s \"\n",
    "              f\"(duration: {sym['duration']/FS:.3f}s, \"\n",
    "              f\"freqs: {sym['low_freq']:.0f}+{sym['high_freq']:.0f} Hz)\")\n",
    "\n",
    "# visualization: detected symbols\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "\n",
    "# plot 1: signal with symbol annotations\n",
    "ax1 = axes[0]\n",
    "ax1.plot(np.arange(len(signal)) / FS, signal, 'b-', linewidth=0.8, alpha=0.7, label='Signal')\n",
    "# mark changepoints\n",
    "for cp_time, _, _, _ in all_cp_times[1:-1]:\n",
    "    ax1.axvline(x=cp_time/FS, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "# annotate symbols\n",
    "y_pos = signal.max() * 0.8\n",
    "for sym in detected_symbols:\n",
    "    if sym['symbol'] not in ['_', '?']:\n",
    "        mid_time = (sym['start_time'] + sym['end_time']) / (2 * FS)\n",
    "        ax1.text(mid_time, y_pos, sym['symbol'], \n",
    "                ha='center', va='bottom', fontsize=14, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "        # draw rectangle around symbol region\n",
    "        ax1.axvspan(sym['start_time']/FS, sym['end_time']/FS, \n",
    "                   alpha=0.2, color='yellow')\n",
    "ax1.set_title(\"Detected DTMF Symbols\", fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel(\"Time (s)\")\n",
    "ax1.set_ylabel(\"Amplitude\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# plot 2: spectrogram with symbol annotations\n",
    "ax2 = axes[1]\n",
    "spectrogram = np.abs(Zxx)\n",
    "im = ax2.pcolormesh(t, f, 20 * np.log10(spectrogram + 1e-10), \n",
    "                   shading='gouraud', cmap='viridis')\n",
    "# mark changepoints\n",
    "for cp_time, _, _, _ in all_cp_times[1:-1]:\n",
    "    ax2.axvline(x=cp_time/FS, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "# annotate symbols\n",
    "for sym in detected_symbols:\n",
    "    if sym['symbol'] not in ['_', '?']:\n",
    "        mid_time = (sym['start_time'] + sym['end_time']) / (2 * FS)\n",
    "        ax2.text(mid_time, 3500, sym['symbol'], \n",
    "                ha='center', va='bottom', fontsize=16, fontweight='bold',\n",
    "                color='white', bbox=dict(boxstyle='round', facecolor='red', alpha=0.8))\n",
    "ax2.set_title(\"Spectrogram with Detected Symbols\", fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel(\"Time (s)\")\n",
    "ax2.set_ylabel(\"Frequency (Hz)\")\n",
    "ax2.set_ylim([0, 4000])\n",
    "plt.colorbar(im, ax=ax2, label=\"Magnitude (dB)\")\n",
    "\n",
    "# plot 3: symbol timeline\n",
    "ax3 = axes[2]\n",
    "y_positions = {}\n",
    "y_counter = 0\n",
    "for sym in detected_symbols:\n",
    "    if sym['symbol'] not in ['_', '?']:\n",
    "        if sym['symbol'] not in y_positions:\n",
    "            y_positions[sym['symbol']] = y_counter\n",
    "            y_counter += 1\n",
    "        y_pos = y_positions[sym['symbol']]\n",
    "        # draw rectangle for symbol\n",
    "        width = (sym['end_time'] - sym['start_time']) / FS\n",
    "        ax3.barh(y_pos, width, left=sym['start_time']/FS, \n",
    "                height=0.8, color=plt.cm.tab10(y_pos % 10), \n",
    "                edgecolor='black', linewidth=1.5)\n",
    "        # add symbol label\n",
    "        mid_time = (sym['start_time'] + sym['end_time']) / (2 * FS)\n",
    "        ax3.text(mid_time, y_pos, sym['symbol'], \n",
    "                ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "ax3.set_title(\"Symbol Timeline\", fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel(\"Time (s)\")\n",
    "ax3.set_ylabel(\"Symbol\")\n",
    "ax3.set_yticks(list(y_positions.values()))\n",
    "ax3.set_yticklabels(list(y_positions.keys()))\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\n=== Summary ===\")\n",
    "print(f\"Total symbols detected: {len([s for s in detected_symbols if s['symbol'] not in ['_', '?']])}\")\n",
    "print(f\"Symbol sequence: {symbol_sequence}\")\n",
    "if len(detected_symbols) > 0:\n",
    "    avg_duration = np.mean([s['duration']/FS for s in detected_symbols if s['symbol'] not in ['_', '?']])\n",
    "    print(f\"Average symbol duration: {avg_duration:.3f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Analyze time period distribution and filter outliers\n",
    "# pattern: CP1 (entry) -> CP2 (out) -> CP1 (entry) -> CP2 (out)...\n",
    "# we compute time between \"out\" and next \"entry\" (gap/silence between symbols)\n",
    "# remove lower outliers (short gaps) while ensuring sum of remaining periods > 0.4s\n",
    "\n",
    "# get all changepoints in chronological order (excluding start/end boundaries)\n",
    "ordered_cps = [cp[0] for cp in all_cp_times[1:-1]]\n",
    "ordered_cps.sort()\n",
    "\n",
    "# compute time periods between consecutive changepoints\n",
    "# these represent: symbol duration, gap duration, symbol duration, gap duration, ...\n",
    "time_periods = []\n",
    "for i in range(len(ordered_cps) - 1):\n",
    "    period_samples = ordered_cps[i+1] - ordered_cps[i]\n",
    "    period_seconds = period_samples / FS\n",
    "    time_periods.append({\n",
    "        'start_cp': ordered_cps[i],\n",
    "        'end_cp': ordered_cps[i+1],\n",
    "        'duration_samples': period_samples,\n",
    "        'duration_seconds': period_seconds,\n",
    "        'index': i\n",
    "    })\n",
    "\n",
    "print(f\"Total time periods between changepoints: {len(time_periods)}\")\n",
    "\n",
    "# analyze distribution\n",
    "period_durations = [p['duration_seconds'] for p in time_periods]\n",
    "mean_duration = np.mean(period_durations)\n",
    "median_duration = np.median(period_durations)\n",
    "std_duration = np.std(period_durations)\n",
    "q25 = np.percentile(period_durations, 25)\n",
    "q75 = np.percentile(period_durations, 75)\n",
    "iqr = q75 - q25\n",
    "\n",
    "print(f\"\\nDistribution statistics:\")\n",
    "print(f\"  Mean: {mean_duration:.4f} s\")\n",
    "print(f\"  Median: {median_duration:.4f} s\")\n",
    "print(f\"  Std: {std_duration:.4f} s\")\n",
    "print(f\"  Q25: {q25:.4f} s, Q75: {q75:.4f} s, IQR: {iqr:.4f} s\")\n",
    "\n",
    "# identify outliers using IQR method\n",
    "# lower outlier: < Q25 - 1.5*IQR\n",
    "# upper outlier: > Q75 + 1.5*IQR\n",
    "lower_bound = q25 - 1.5 * iqr\n",
    "upper_bound = q75 + 1.5 * iqr\n",
    "\n",
    "lower_outliers = [p for p in time_periods if p['duration_seconds'] < lower_bound]\n",
    "upper_outliers = [p for p in time_periods if p['duration_seconds'] > upper_bound]\n",
    "inliers = [p for p in time_periods if lower_bound <= p['duration_seconds'] <= upper_bound]\n",
    "\n",
    "print(f\"\\nOutlier detection (IQR method):\")\n",
    "print(f\"  Lower bound: {lower_bound:.4f} s\")\n",
    "print(f\"  Upper bound: {upper_bound:.4f} s\")\n",
    "print(f\"  Lower outliers: {len(lower_outliers)}\")\n",
    "print(f\"  Upper outliers: {len(upper_outliers)}\")\n",
    "print(f\"  Inliers: {len(inliers)}\")\n",
    "\n",
    "# filter lower outliers with constraint: sum of remaining periods > 0.4s\n",
    "# we want to remove as many lower outliers as possible while maintaining this constraint\n",
    "magic_threshold = 0.4  # seconds - minimum total duration of remaining periods\n",
    "\n",
    "# sort lower outliers by duration (shortest first) to remove them in order\n",
    "lower_outliers_sorted = sorted(lower_outliers, key=lambda x: x['duration_seconds'])\n",
    "\n",
    "# compute initial sum of all periods\n",
    "total_duration = sum(p['duration_seconds'] for p in time_periods)\n",
    "print(f\"\\nInitial total duration: {total_duration:.4f} s\")\n",
    "\n",
    "# iteratively remove lower outliers, checking constraint\n",
    "filtered_periods = time_periods.copy()\n",
    "removed_outliers = []\n",
    "\n",
    "for outlier in lower_outliers_sorted:\n",
    "    # check if removing this outlier would violate constraint\n",
    "    test_duration = sum(p['duration_seconds'] for p in filtered_periods \n",
    "                       if p['index'] != outlier['index'])\n",
    "    \n",
    "    if test_duration > magic_threshold:\n",
    "        # safe to remove\n",
    "        filtered_periods = [p for p in filtered_periods if p['index'] != outlier['index']]\n",
    "        removed_outliers.append(outlier)\n",
    "    else:\n",
    "        # cannot remove without violating constraint\n",
    "        break\n",
    "\n",
    "final_duration = sum(p['duration_seconds'] for p in filtered_periods)\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"  Removed {len(removed_outliers)} lower outliers\")\n",
    "print(f\"  Remaining periods: {len(filtered_periods)}\")\n",
    "print(f\"  Final total duration: {final_duration:.4f} s\")\n",
    "print(f\"  Constraint satisfied: {final_duration > magic_threshold} (threshold: {magic_threshold} s)\")\n",
    "\n",
    "# get filtered changepoints (only keep CPs that are boundaries of remaining periods)\n",
    "filtered_cp_indices = set()\n",
    "for p in filtered_periods:\n",
    "    filtered_cp_indices.add(p['start_cp'])\n",
    "    filtered_cp_indices.add(p['end_cp'])\n",
    "\n",
    "filtered_cps = sorted(list(filtered_cp_indices))\n",
    "print(f\"  Filtered changepoints: {len(filtered_cps)} (from {len(ordered_cps)} original)\")\n",
    "\n",
    "# visualization: distribution analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# plot 1: histogram of time period distribution\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(period_durations, bins=30, alpha=0.7, color='blue', edgecolor='black', label='All periods')\n",
    "ax1.axvline(mean_duration, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_duration:.4f}s')\n",
    "ax1.axvline(median_duration, color='green', linestyle='--', linewidth=2, label=f'Median: {median_duration:.4f}s')\n",
    "ax1.axvline(lower_bound, color='orange', linestyle=':', linewidth=2, label=f'Lower bound: {lower_bound:.4f}s')\n",
    "ax1.axvline(upper_bound, color='orange', linestyle=':', linewidth=2, label=f'Upper bound: {upper_bound:.4f}s')\n",
    "ax1.set_title(\"Time Period Distribution (Between Changepoints)\", fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel(\"Duration (seconds)\")\n",
    "ax1.set_ylabel(\"Frequency\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# plot 2: box plot showing outliers\n",
    "ax2 = axes[0, 1]\n",
    "bp = ax2.boxplot(period_durations, vert=True, patch_artist=True, \n",
    "                showmeans=True, meanline=True)\n",
    "bp['boxes'][0].set_facecolor('lightblue')\n",
    "bp['boxes'][0].set_alpha(0.7)\n",
    "# highlight outliers\n",
    "for outlier in lower_outliers:\n",
    "    ax2.plot(1, outlier['duration_seconds'], 'ro', markersize=8, alpha=0.7, label='Lower outlier' if outlier == lower_outliers[0] else '')\n",
    "for outlier in upper_outliers:\n",
    "    ax2.plot(1, outlier['duration_seconds'], 'go', markersize=8, alpha=0.7, label='Upper outlier' if outlier == upper_outliers[0] else '')\n",
    "ax2.axhline(magic_threshold, color='purple', linestyle='--', linewidth=2, \n",
    "           label=f'Magic threshold: {magic_threshold}s')\n",
    "ax2.set_title(\"Box Plot with Outliers\", fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel(\"Duration (seconds)\")\n",
    "ax2.set_xticklabels(['Time Periods'])\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# plot 3: before/after filtering comparison\n",
    "ax3 = axes[1, 0]\n",
    "# before filtering\n",
    "ax3.hist(period_durations, bins=30, alpha=0.5, color='blue', edgecolor='black', \n",
    "        label=f'Before ({len(time_periods)} periods)')\n",
    "# after filtering\n",
    "filtered_durations = [p['duration_seconds'] for p in filtered_periods]\n",
    "ax3.hist(filtered_durations, bins=30, alpha=0.7, color='green', edgecolor='black', \n",
    "        label=f'After ({len(filtered_periods)} periods)')\n",
    "ax3.axvline(magic_threshold, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Magic threshold: {magic_threshold}s')\n",
    "ax3.set_title(\"Before/After Filtering Comparison\", fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel(\"Duration (seconds)\")\n",
    "ax3.set_ylabel(\"Frequency\")\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# plot 4: timeline showing removed periods\n",
    "ax4 = axes[1, 1]\n",
    "# plot all periods\n",
    "for i, p in enumerate(time_periods):\n",
    "    color = 'red' if p in removed_outliers else 'green'\n",
    "    alpha = 0.3 if p in removed_outliers else 0.7\n",
    "    ax4.barh(i, p['duration_seconds'], left=p['start_cp']/FS, \n",
    "            color=color, alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "ax4.set_title(f\"Timeline: Removed vs Kept Periods\\n(Red=removed, Green=kept)\", \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax4.set_xlabel(\"Time (seconds)\")\n",
    "ax4.set_ylabel(\"Period Index\")\n",
    "ax4.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\n=== Filtering Summary ===\")\n",
    "print(f\"Original periods: {len(time_periods)}\")\n",
    "print(f\"Removed lower outliers: {len(removed_outliers)}\")\n",
    "print(f\"Remaining periods: {len(filtered_periods)}\")\n",
    "print(f\"Original total duration: {total_duration:.4f} s\")\n",
    "print(f\"Final total duration: {final_duration:.4f} s\")\n",
    "print(f\"Removed duration: {total_duration - final_duration:.4f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba81d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Match periods with symbols and frequency pairs\n",
    "# use ground truth symbols from y_train[i] for matching\n",
    "# get the signal index (assuming we're processing signal from X_train[signal_idx])\n",
    "# NOTE: make sure signal_idx matches the signal variable used above\n",
    "# if signal = X_train[0], then signal_idx = 0\n",
    "# if signal = X_train[2], then signal_idx = 2, etc.\n",
    "signal_idx = 0  # change this to match the signal being processed (signal = X_train[signal_idx])\n",
    "ground_truth_symbols = y_train[signal_idx]  # get ground truth symbols\n",
    "print(f\"Using ground truth symbols for signal {signal_idx}: {ground_truth_symbols}\")\n",
    "\n",
    "def get_valid_symbols_from_ground_truth(ground_truth_symbols):\n",
    "    \"\"\"convert ground truth symbol list to format compatible with matching\"\"\"\n",
    "    # create symbol objects with timing information (we'll match periods to these)\n",
    "    symbols = []\n",
    "    for i, sym in enumerate(ground_truth_symbols):\n",
    "        symbols.append({\n",
    "            'symbol': sym,\n",
    "            'index': i,\n",
    "            'start_time': None,  # will be set by matching\n",
    "            'end_time': None\n",
    "        })\n",
    "    return symbols\n",
    "\n",
    "def get_valid_symbols(detected_symbols):\n",
    "    \"\"\"extract valid symbols (excluding silence and unknown)\"\"\"\n",
    "    return [s for s in detected_symbols if s['symbol'] not in ['_', '?']]\n",
    "\n",
    "def order_periods_by_duration(periods, descending=True):\n",
    "    \"\"\"order time periods by duration\"\"\"\n",
    "    return sorted(periods, key=lambda x: x['duration_seconds'], reverse=descending)\n",
    "\n",
    "def select_n_biggest_periods(periods, n):\n",
    "    \"\"\"select the n biggest periods by duration\"\"\"\n",
    "    ordered_by_duration = sorted(periods, key=lambda x: x['duration_seconds'], reverse=True)\n",
    "    return ordered_by_duration[:n]\n",
    "\n",
    "def order_periods_by_time(periods):\n",
    "    \"\"\"order periods chronologically by start time\"\"\"\n",
    "    return sorted(periods, key=lambda x: x['start_cp'])\n",
    "\n",
    "def order_symbols_by_time(symbols):\n",
    "    \"\"\"order symbols chronologically by start time\"\"\"\n",
    "    return sorted(symbols, key=lambda x: x['start_time'] if x['start_time'] is not None else 0)\n",
    "\n",
    "def find_active_frequencies_in_period(period, low_freq_clusters, high_freq_clusters, \n",
    "                                     frame_step, energy_threshold_ratio=0.05, cp_tolerance=3000):\n",
    "    \"\"\"\n",
    "    find which low and high frequencies are active during a time period\n",
    "    since periods are defined by changepoints from different frequency clusters,\n",
    "    we check which clusters have changepoints that define or are near this period\n",
    "    uses multiple methods with increasing permissiveness\n",
    "    \"\"\"\n",
    "    start_time = period['start_cp']\n",
    "    end_time = period['end_cp']\n",
    "    period_mid = (start_time + end_time) / 2\n",
    "    period_duration = end_time - start_time\n",
    "    \n",
    "    active_low = []\n",
    "    active_high = []\n",
    "    \n",
    "    # method 1: check which clusters have changepoints near the period boundaries\n",
    "    # if a cluster has changepoints near start_cp or end_cp, it likely defines this period\n",
    "    for cp_dict in low_freq_clusters:\n",
    "        cps = sorted(cp_dict['changepoints'])\n",
    "        # check if any changepoint is near the period boundaries\n",
    "        near_start = any(abs(cp - start_time) < cp_tolerance for cp in cps)\n",
    "        near_end = any(abs(cp - end_time) < cp_tolerance for cp in cps)\n",
    "        # also check if period overlaps with a segment between changepoints\n",
    "        period_in_segment = False\n",
    "        for i in range(len(cps) - 1):\n",
    "            if cps[i] <= period_mid <= cps[i+1]:\n",
    "                period_in_segment = True\n",
    "                break\n",
    "        \n",
    "        if near_start or near_end or period_in_segment:\n",
    "            # verify with energy check\n",
    "            start_frame = max(0, int(start_time / frame_step))\n",
    "            end_frame = min(len(cp_dict['energy_signal']), int(end_time / frame_step) + 1)\n",
    "            if start_frame < end_frame:\n",
    "                segment_energy = cp_dict['energy_signal'][start_frame:end_frame]\n",
    "                if len(segment_energy) > 0:\n",
    "                    max_energy = np.max(cp_dict['energy_signal'])\n",
    "                    avg_energy = np.mean(segment_energy)\n",
    "                    energy_ratio = avg_energy / max_energy if max_energy > 0 else 0\n",
    "                    \n",
    "                    # if changepoints define the period OR energy is above threshold, include it\n",
    "                    if (near_start or near_end or period_in_segment) or (energy_ratio > energy_threshold_ratio):\n",
    "                        active_low.append({\n",
    "                            'freq': cp_dict['selected_freq'],\n",
    "                            'cluster_id': cp_dict['cluster_id'],\n",
    "                            'avg_energy': float(avg_energy),\n",
    "                            'max_energy': float(max_energy),\n",
    "                            'energy_ratio': float(energy_ratio),\n",
    "                            'method': 'changepoint' if (near_start or near_end or period_in_segment) else 'energy'\n",
    "                        })\n",
    "    \n",
    "    for cp_dict in high_freq_clusters:\n",
    "        cps = sorted(cp_dict['changepoints'])\n",
    "        # check if any changepoint is near the period boundaries\n",
    "        near_start = any(abs(cp - start_time) < cp_tolerance for cp in cps)\n",
    "        near_end = any(abs(cp - end_time) < cp_tolerance for cp in cps)\n",
    "        # also check if period overlaps with a segment between changepoints\n",
    "        period_in_segment = False\n",
    "        for i in range(len(cps) - 1):\n",
    "            if cps[i] <= period_mid <= cps[i+1]:\n",
    "                period_in_segment = True\n",
    "                break\n",
    "        \n",
    "        if near_start or near_end or period_in_segment:\n",
    "            # verify with energy check\n",
    "            start_frame = max(0, int(start_time / frame_step))\n",
    "            end_frame = min(len(cp_dict['energy_signal']), int(end_time / frame_step) + 1)\n",
    "            if start_frame < end_frame:\n",
    "                segment_energy = cp_dict['energy_signal'][start_frame:end_frame]\n",
    "                if len(segment_energy) > 0:\n",
    "                    max_energy = np.max(cp_dict['energy_signal'])\n",
    "                    avg_energy = np.mean(segment_energy)\n",
    "                    energy_ratio = avg_energy / max_energy if max_energy > 0 else 0\n",
    "                    \n",
    "                    # if changepoints define the period OR energy is above threshold, include it\n",
    "                    if (near_start or near_end or period_in_segment) or (energy_ratio > energy_threshold_ratio):\n",
    "                        active_high.append({\n",
    "                            'freq': cp_dict['selected_freq'],\n",
    "                            'cluster_id': cp_dict['cluster_id'],\n",
    "                            'avg_energy': float(avg_energy),\n",
    "                            'max_energy': float(max_energy),\n",
    "                            'energy_ratio': float(energy_ratio),\n",
    "                            'method': 'changepoint' if (near_start or near_end or period_in_segment) else 'energy'\n",
    "                        })\n",
    "    \n",
    "    # if still no frequencies found, use pure energy-based method as last resort\n",
    "    if len(active_low) == 0:\n",
    "        for cp_dict in low_freq_clusters:\n",
    "            start_frame = max(0, int(start_time / frame_step))\n",
    "            end_frame = min(len(cp_dict['energy_signal']), int(end_time / frame_step) + 1)\n",
    "            if start_frame < end_frame:\n",
    "                segment_energy = cp_dict['energy_signal'][start_frame:end_frame]\n",
    "                if len(segment_energy) > 0:\n",
    "                    max_energy = np.max(cp_dict['energy_signal'])\n",
    "                    avg_energy = np.mean(segment_energy)\n",
    "                    energy_ratio = avg_energy / max_energy if max_energy > 0 else 0\n",
    "                    if energy_ratio > energy_threshold_ratio:\n",
    "                        active_low.append({\n",
    "                            'freq': cp_dict['selected_freq'],\n",
    "                            'cluster_id': cp_dict['cluster_id'],\n",
    "                            'avg_energy': float(avg_energy),\n",
    "                            'max_energy': float(max_energy),\n",
    "                            'energy_ratio': float(energy_ratio),\n",
    "                            'method': 'energy_fallback'\n",
    "                        })\n",
    "    \n",
    "    if len(active_high) == 0:\n",
    "        for cp_dict in high_freq_clusters:\n",
    "            start_frame = max(0, int(start_time / frame_step))\n",
    "            end_frame = min(len(cp_dict['energy_signal']), int(end_time / frame_step) + 1)\n",
    "            if start_frame < end_frame:\n",
    "                segment_energy = cp_dict['energy_signal'][start_frame:end_frame]\n",
    "                if len(segment_energy) > 0:\n",
    "                    max_energy = np.max(cp_dict['energy_signal'])\n",
    "                    avg_energy = np.mean(segment_energy)\n",
    "                    energy_ratio = avg_energy / max_energy if max_energy > 0 else 0\n",
    "                    if energy_ratio > energy_threshold_ratio:\n",
    "                        active_high.append({\n",
    "                            'freq': cp_dict['selected_freq'],\n",
    "                            'cluster_id': cp_dict['cluster_id'],\n",
    "                            'avg_energy': float(avg_energy),\n",
    "                            'max_energy': float(max_energy),\n",
    "                            'energy_ratio': float(energy_ratio),\n",
    "                            'method': 'energy_fallback'\n",
    "                        })\n",
    "    \n",
    "    # final fallback: if still no frequencies, take the one with highest energy in the period\n",
    "    # this handles edge cases where thresholds are too strict\n",
    "    if len(active_low) == 0 and len(low_freq_clusters) > 0:\n",
    "        best_low = None\n",
    "        best_energy_ratio = 0\n",
    "        for cp_dict in low_freq_clusters:\n",
    "            start_frame = max(0, int(start_time / frame_step))\n",
    "            end_frame = min(len(cp_dict['energy_signal']), int(end_time / frame_step) + 1)\n",
    "            if start_frame < end_frame:\n",
    "                segment_energy = cp_dict['energy_signal'][start_frame:end_frame]\n",
    "                if len(segment_energy) > 0:\n",
    "                    max_energy = np.max(cp_dict['energy_signal'])\n",
    "                    avg_energy = np.mean(segment_energy)\n",
    "                    energy_ratio = avg_energy / max_energy if max_energy > 0 else 0\n",
    "                    if energy_ratio > best_energy_ratio:\n",
    "                        best_energy_ratio = energy_ratio\n",
    "                        best_low = {\n",
    "                            'freq': cp_dict['selected_freq'],\n",
    "                            'cluster_id': cp_dict['cluster_id'],\n",
    "                            'avg_energy': float(avg_energy),\n",
    "                            'max_energy': float(max_energy),\n",
    "                            'energy_ratio': float(energy_ratio),\n",
    "                            'method': 'best_energy_fallback'\n",
    "                        }\n",
    "        if best_low is not None:\n",
    "            active_low.append(best_low)\n",
    "    \n",
    "    if len(active_high) == 0 and len(high_freq_clusters) > 0:\n",
    "        best_high = None\n",
    "        best_energy_ratio = 0\n",
    "        for cp_dict in high_freq_clusters:\n",
    "            start_frame = max(0, int(start_time / frame_step))\n",
    "            end_frame = min(len(cp_dict['energy_signal']), int(end_time / frame_step) + 1)\n",
    "            if start_frame < end_frame:\n",
    "                segment_energy = cp_dict['energy_signal'][start_frame:end_frame]\n",
    "                if len(segment_energy) > 0:\n",
    "                    max_energy = np.max(cp_dict['energy_signal'])\n",
    "                    avg_energy = np.mean(segment_energy)\n",
    "                    energy_ratio = avg_energy / max_energy if max_energy > 0 else 0\n",
    "                    if energy_ratio > best_energy_ratio:\n",
    "                        best_energy_ratio = energy_ratio\n",
    "                        best_high = {\n",
    "                            'freq': cp_dict['selected_freq'],\n",
    "                            'cluster_id': cp_dict['cluster_id'],\n",
    "                            'avg_energy': float(avg_energy),\n",
    "                            'max_energy': float(max_energy),\n",
    "                            'energy_ratio': float(energy_ratio),\n",
    "                            'method': 'best_energy_fallback'\n",
    "                        }\n",
    "        if best_high is not None:\n",
    "            active_high.append(best_high)\n",
    "    \n",
    "    # sort by energy ratio (strongest first), but prioritize changepoint method\n",
    "    active_low.sort(key=lambda x: (x.get('method') != 'changepoint', -x['energy_ratio']))\n",
    "    active_high.sort(key=lambda x: (x.get('method') != 'changepoint', -x['energy_ratio']))\n",
    "    \n",
    "    return {\n",
    "        'low_freqs': [f['freq'] for f in active_low],\n",
    "        'high_freqs': [f['freq'] for f in active_high],\n",
    "        'low_clusters': active_low,\n",
    "        'high_clusters': active_high\n",
    "    }\n",
    "\n",
    "def match_frequency_pair_to_symbol(low_freq, high_freq, dtmf_low_freqs, dtmf_high_freqs, dtmf_symbols):\n",
    "    \"\"\"map a frequency pair to DTMF symbol\"\"\"\n",
    "    def freq_to_dtmf_index(freq, freq_list):\n",
    "        distances = [abs(freq - dtmf_f) for dtmf_f in freq_list]\n",
    "        min_idx = np.argmin(distances)\n",
    "        min_dist = distances[min_idx]\n",
    "        if min_dist < 50:  # tolerance\n",
    "            return min_idx\n",
    "        return None\n",
    "    \n",
    "    low_idx = freq_to_dtmf_index(low_freq, dtmf_low_freqs)\n",
    "    high_idx = freq_to_dtmf_index(high_freq, dtmf_high_freqs)\n",
    "    \n",
    "    if low_idx is not None and high_idx is not None:\n",
    "        return dtmf_symbols[low_idx][high_idx]\n",
    "    return None\n",
    "\n",
    "def complete_period_symbol_matching(filtered_periods, ground_truth_symbols, \n",
    "                                   low_freq_clusters, high_freq_clusters,\n",
    "                                   frame_step, dtmf_low_freqs, dtmf_high_freqs, dtmf_symbols):\n",
    "    \"\"\"\n",
    "    complete pipeline: match periods with symbols and frequency pairs\n",
    "    1. get number of valid symbols from ground truth\n",
    "    2. select N biggest periods (where N = number of symbols)\n",
    "    3. order selected periods by time (chronologically)\n",
    "    4. match: first period (by time) -> first symbol (in order), etc.\n",
    "    5. for each period, find frequency pair and verify with symbol\n",
    "    returns list of matched results with period, symbol, and frequency information\n",
    "    \"\"\"\n",
    "    # step 1: get valid symbols from ground truth\n",
    "    valid_symbols = get_valid_symbols_from_ground_truth(ground_truth_symbols)\n",
    "    n_symbols = len(valid_symbols)\n",
    "    print(f\"=== Period-Symbol Matching ===\")\n",
    "    print(f\"Number of ground truth symbols: {n_symbols}\")\n",
    "    print(f\"Ground truth symbols: {ground_truth_symbols}\")\n",
    "    print(f\"All filtered periods: {len(filtered_periods)}\")\n",
    "    \n",
    "    # step 2: select N biggest periods (where N = number of symbols)\n",
    "    selected_periods = select_n_biggest_periods(filtered_periods, n_symbols)\n",
    "    print(f\"\\nSelected {len(selected_periods)} biggest periods (by duration):\")\n",
    "    for i, p in enumerate(selected_periods):\n",
    "        print(f\"  {i+1}. Duration: {p['duration_seconds']:.4f} s, \"\n",
    "              f\"Time: [{p['start_cp']/FS:.3f}, {p['end_cp']/FS:.3f}] s\")\n",
    "    \n",
    "    # step 3: order selected periods by time (chronologically)\n",
    "    periods_ordered_by_time = order_periods_by_time(selected_periods)\n",
    "    print(f\"\\nSelected periods ordered by time:\")\n",
    "    for i, p in enumerate(periods_ordered_by_time):\n",
    "        print(f\"  {i+1}. Time: [{p['start_cp']/FS:.3f}, {p['end_cp']/FS:.3f}] s, \"\n",
    "              f\"Duration: {p['duration_seconds']:.4f} s\")\n",
    "    \n",
    "    # step 4: symbols are already in order (ground truth order)\n",
    "    # assign time information from periods to symbols\n",
    "    print(f\"\\nSymbols (ground truth order):\")\n",
    "    for i, s in enumerate(valid_symbols):\n",
    "        print(f\"  {i+1}. Symbol: '{s['symbol']}'\")\n",
    "    \n",
    "    # step 5: match periods (by time) with symbols (in ground truth order)\n",
    "    print(f\"\\nMatched {len(periods_ordered_by_time)} period-symbol pairs (by time order):\")\n",
    "    \n",
    "    # step 6: for each match, find active frequencies and verify symbol\n",
    "    complete_matches = []\n",
    "    for i, (period, symbol) in enumerate(zip(periods_ordered_by_time, valid_symbols)):\n",
    "        # find active frequencies in this period\n",
    "        active_freqs = find_active_frequencies_in_period(\n",
    "            period, low_freq_clusters, high_freq_clusters, frame_step\n",
    "        )\n",
    "        \n",
    "        # get primary frequency pair (strongest in each group)\n",
    "        primary_low = active_freqs['low_freqs'][0] if active_freqs['low_freqs'] else None\n",
    "        primary_high = active_freqs['high_freqs'][0] if active_freqs['high_freqs'] else None\n",
    "        \n",
    "        # verify symbol matches frequency pair\n",
    "        verified_symbol = None\n",
    "        if primary_low is not None and primary_high is not None:\n",
    "            verified_symbol = match_frequency_pair_to_symbol(\n",
    "                primary_low, primary_high, dtmf_low_freqs, dtmf_high_freqs, dtmf_symbols\n",
    "            )\n",
    "        \n",
    "        complete_match = {\n",
    "            'period': period,\n",
    "            'assigned_symbol': symbol['symbol'],\n",
    "            'verified_symbol': verified_symbol,\n",
    "            'primary_low_freq': primary_low,\n",
    "            'primary_high_freq': primary_high,\n",
    "            'all_low_freqs': active_freqs['low_freqs'],\n",
    "            'all_high_freqs': active_freqs['high_freqs'],\n",
    "            'match_index': i,\n",
    "            'symbol_match': (symbol['symbol'] == verified_symbol) if verified_symbol else False\n",
    "        }\n",
    "        complete_matches.append(complete_match)\n",
    "        \n",
    "        # assign time information to symbol\n",
    "        symbol['start_time'] = period['start_cp']\n",
    "        symbol['end_time'] = period['end_cp']\n",
    "        \n",
    "        print(f\"  Match {i+1}:\")\n",
    "        print(f\"    Period: {period['duration_seconds']:.4f} s \"\n",
    "              f\"([{period['start_cp']/FS:.3f}, {period['end_cp']/FS:.3f}] s)\")\n",
    "        print(f\"    Assigned symbol: '{symbol['symbol']}' \"\n",
    "              f\"([{period['start_cp']/FS:.3f}, {period['end_cp']/FS:.3f}] s)\")\n",
    "        print(f\"    Active freqs: Low={active_freqs['low_freqs']}, High={active_freqs['high_freqs']}\")\n",
    "        if len(active_freqs['low_clusters']) > 0:\n",
    "            print(f\"    Low freq details: {[(f['freq'], f['cluster_id']) for f in active_freqs['low_clusters']]}\")\n",
    "        if len(active_freqs['high_clusters']) > 0:\n",
    "            print(f\"    High freq details: {[(f['freq'], f['cluster_id']) for f in active_freqs['high_clusters']]}\")\n",
    "        if primary_low and primary_high:\n",
    "            print(f\"    Primary pair: {primary_low:.0f} Hz + {primary_high:.0f} Hz\")\n",
    "            print(f\"    Verified symbol: '{verified_symbol}'\")\n",
    "            print(f\"    Match: {'✓' if complete_match['symbol_match'] else '✗'}\")\n",
    "        else:\n",
    "            print(f\"    Warning: Missing frequency pair\")\n",
    "            if len(active_freqs['low_freqs']) == 0:\n",
    "                print(f\"      No low frequencies found for this period\")\n",
    "            if len(active_freqs['high_freqs']) == 0:\n",
    "                print(f\"      No high frequencies found for this period\")\n",
    "    \n",
    "    return complete_matches\n",
    "\n",
    "# execute the complete matching pipeline using ground truth symbols\n",
    "complete_matches = complete_period_symbol_matching(\n",
    "    filtered_periods, ground_truth_symbols,\n",
    "    low_freq_clusters, high_freq_clusters,\n",
    "    frame_step, dtmf_low_freqs, dtmf_high_freqs, dtmf_symbols\n",
    ")\n",
    "\n",
    "# visualization: show one complete example\n",
    "if len(complete_matches) > 0:\n",
    "    example_idx = 0  # show first match as example\n",
    "    example = complete_matches[example_idx]\n",
    "    \n",
    "    print(f\"\\n=== Complete Example (Match {example_idx+1}) ===\")\n",
    "    print(f\"Period duration: {example['period']['duration_seconds']:.4f} s\")\n",
    "    print(f\"Time range: [{example['period']['start_cp']/FS:.3f}, {example['period']['end_cp']/FS:.3f}] s\")\n",
    "    print(f\"Assigned symbol: '{example['assigned_symbol']}'\")\n",
    "    if example['primary_low_freq'] and example['primary_high_freq']:\n",
    "        print(f\"Primary frequency pair: {example['primary_low_freq']:.0f} Hz + {example['primary_high_freq']:.0f} Hz\")\n",
    "    print(f\"Verified symbol: '{example['verified_symbol']}'\")\n",
    "    print(f\"All low frequencies: {example['all_low_freqs']}\")\n",
    "    print(f\"All high frequencies: {example['all_high_freqs']}\")\n",
    "    print(f\"Symbol match: {'✓ CORRECT' if example['symbol_match'] else '✗ MISMATCH'}\")\n",
    "    \n",
    "    # visualize the example\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(16, 10))\n",
    "    \n",
    "    # plot 1: signal with period highlighted\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(np.arange(len(signal)) / FS, signal, 'b-', linewidth=0.8, alpha=0.5, label='Signal')\n",
    "    # highlight the period\n",
    "    period_start = example['period']['start_cp'] / FS\n",
    "    period_end = example['period']['end_cp'] / FS\n",
    "    ax1.axvspan(period_start, period_end, alpha=0.3, color='yellow', \n",
    "               label=f\"Period: {example['period']['duration_seconds']:.4f} s\")\n",
    "    ax1.axvline(period_start, color='red', linestyle='--', linewidth=2, label='Start CP')\n",
    "    ax1.axvline(period_end, color='red', linestyle='--', linewidth=2, label='End CP')\n",
    "    ax1.set_title(f\"Example: Period {example_idx+1} - Symbol '{example['assigned_symbol']}'\", \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel(\"Time (s)\")\n",
    "    ax1.set_ylabel(\"Amplitude\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # plot 2: spectrogram with period and frequencies\n",
    "    ax2 = axes[1]\n",
    "    spectrogram = np.abs(Zxx)\n",
    "    im = ax2.pcolormesh(t, f, 20 * np.log10(spectrogram + 1e-10), \n",
    "                       shading='gouraud', cmap='viridis')\n",
    "    # highlight period\n",
    "    ax2.axvspan(period_start, period_end, alpha=0.2, color='yellow')\n",
    "    ax2.axvline(period_start, color='red', linestyle='--', linewidth=2)\n",
    "    ax2.axvline(period_end, color='red', linestyle='--', linewidth=2)\n",
    "    # mark active frequencies\n",
    "    if example['primary_low_freq']:\n",
    "        ax2.axhline(example['primary_low_freq'], color='cyan', linestyle='-', \n",
    "                   linewidth=3, label=f\"Low: {example['primary_low_freq']:.0f} Hz\")\n",
    "    if example['primary_high_freq']:\n",
    "        ax2.axhline(example['primary_high_freq'], color='magenta', linestyle='-', \n",
    "                   linewidth=3, label=f\"High: {example['primary_high_freq']:.0f} Hz\")\n",
    "    # add symbol annotation\n",
    "    mid_time = (period_start + period_end) / 2\n",
    "    ax2.text(mid_time, 3500, example['assigned_symbol'], \n",
    "            ha='center', va='bottom', fontsize=20, fontweight='bold',\n",
    "            color='white', bbox=dict(boxstyle='round', facecolor='red', alpha=0.9))\n",
    "    ax2.set_title(f\"Spectrogram: Active Frequencies for '{example['assigned_symbol']}'\", \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel(\"Time (s)\")\n",
    "    ax2.set_ylabel(\"Frequency (Hz)\")\n",
    "    ax2.set_ylim([0, 4000])\n",
    "    ax2.legend()\n",
    "    plt.colorbar(im, ax=ax2, label=\"Magnitude (dB)\")\n",
    "    \n",
    "    # plot 3: energy signals for active frequencies\n",
    "    ax3 = axes[2]\n",
    "    # find energy signals for primary frequencies\n",
    "    for cp_dict in low_freq_clusters + high_freq_clusters:\n",
    "        if example['primary_low_freq'] and cp_dict['selected_freq'] == example['primary_low_freq']:\n",
    "            ax3.plot(t, cp_dict['energy_signal'], 'c-', linewidth=2, \n",
    "                    label=f\"Low: {example['primary_low_freq']:.0f} Hz\", alpha=0.8)\n",
    "        elif example['primary_high_freq'] and cp_dict['selected_freq'] == example['primary_high_freq']:\n",
    "            ax3.plot(t, cp_dict['energy_signal'], 'm-', linewidth=2, \n",
    "                    label=f\"High: {example['primary_high_freq']:.0f} Hz\", alpha=0.8)\n",
    "    # highlight period\n",
    "    ax3.axvspan(period_start, period_end, alpha=0.2, color='yellow')\n",
    "    ax3.axvline(period_start, color='red', linestyle='--', linewidth=2)\n",
    "    ax3.axvline(period_end, color='red', linestyle='--', linewidth=2)\n",
    "    ax3.set_title(f\"Energy Signals: Frequency Pair for '{example['assigned_symbol']}'\", \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel(\"Time (s)\")\n",
    "    ax3.set_ylabel(\"Energy\")\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # summary of all matches\n",
    "    print(f\"\\n=== All Matches Summary ===\")\n",
    "    for i, match in enumerate(complete_matches):\n",
    "        status = \"✓\" if match['symbol_match'] else \"✗\"\n",
    "        if match['primary_low_freq'] and match['primary_high_freq']:\n",
    "            print(f\"{status} Match {i+1}: '{match['assigned_symbol']}' \"\n",
    "                  f\"(period: {match['period']['duration_seconds']:.4f}s, \"\n",
    "                  f\"freqs: {match['primary_low_freq']:.0f}+{match['primary_high_freq']:.0f} Hz)\")\n",
    "        else:\n",
    "            print(f\"{status} Match {i+1}: '{match['assigned_symbol']}' \"\n",
    "                  f\"(period: {match['period']['duration_seconds']:.4f}s, no freq pair)\")\n",
    "else:\n",
    "    print(\"\\nNo matches found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa8aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = 22050  # sampling frequency (Hz)\n",
    "\n",
    "X_train = np.load(\"X_train.npy\", allow_pickle=True).tolist()\n",
    "y_train = np.load(\"y_train.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d2c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, symbols = X_train[2], y_train[2]\n",
    "print(\" \".join(symbols))\n",
    "\n",
    "\n",
    "IPython.display.Audio(signal, rate=FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot FFT of the signal\n",
    "fft_vals = np.abs(fft(signal))\n",
    "freqs = np.fft.fftfreq(len(signal), 1/FS)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(freqs[:len(freqs)//2], fft_vals[:len(fft_vals)//2])\n",
    "plt.title(\"FFT of selected signal\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7d5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"X_test.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a43eca",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1442ba",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cfddea",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f995b6e",
   "metadata": {},
   "source": [
    "## Utility functions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dms2dd(s):\n",
    "    \"\"\"Convert longitude and latitude strings to float.\"\"\"\n",
    "    # https://stackoverflow.com/a/50193328\n",
    "    # example: s =  \"\"\"48°51'18\"\"\"\n",
    "    degrees, minutes, seconds = re.split(\"[°'\\\"]+\", s[:-1])\n",
    "    direction = s[-1]\n",
    "    dd = float(degrees) + float(minutes) / 60 + float(seconds) / (60 * 60)\n",
    "    if direction in (\"S\", \"W\"):\n",
    "        dd *= -1\n",
    "    return dd\n",
    "\n",
    "def get_geodesic_distance(point_1, point_2) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance (in km) between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    https://stackoverflow.com/a/4913653\n",
    "    \"\"\"\n",
    "\n",
    "    lon1, lat1 = point_1\n",
    "    lon2, lat2 = point_2\n",
    "\n",
    "    # convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371  # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r    \n",
    "\n",
    "def get_exponential_similarity(condensed_distance_matrix, bandwidth, threshold):\n",
    "    exp_similarity = np.exp(-(condensed_distance_matrix**2) / bandwidth / bandwidth)\n",
    "    res_arr = np.where(exp_similarity > threshold, exp_similarity, 0.0)\n",
    "    return res_arr\n",
    "\n",
    "def is_connected(graph) -> bool:\n",
    "    return graph.is_connected()\n",
    "\n",
    "def fig_ax(figsize=(15, 3)):\n",
    "    return plt.subplots(figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc40907",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df, stations_df, description = load_molene_meteo_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ebe330",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"temp\"] = data_df['t']- 273.15  # temperature in Celsius\n",
    "temperature_df = data_df.pivot(index=\"date\", values=\"temp\", columns=\"station_name\")\n",
    "temperature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec2750d",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f765fa",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b26774",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed75b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all signals in the dataset and save results\n",
    "import json\n",
    "import os\n",
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "# create output directory\n",
    "output_dir = \"refs/tps/assignment3/data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def process_single_signal(signal, ground_truth_symbols, signal_idx, log_file):\n",
    "    \"\"\"\n",
    "    process a single signal through the complete DTMF detection pipeline\n",
    "    returns all results as dictionaries\n",
    "    \"\"\"\n",
    "    log_file.write(f\"\\n{'='*80}\\n\")\n",
    "    log_file.write(f\"Processing Signal {signal_idx}\\n\")\n",
    "    log_file.write(f\"{'='*80}\\n\")\n",
    "    log_file.write(f\"Signal length: {len(signal)} samples ({len(signal)/FS:.3f} seconds)\\n\")\n",
    "    log_file.write(f\"Ground truth symbols: {ground_truth_symbols}\\n\")\n",
    "    log_file.flush()\n",
    "    \n",
    "    results = {\n",
    "        'signal_idx': signal_idx,\n",
    "        'signal_length': len(signal),\n",
    "        'ground_truth_symbols': ground_truth_symbols,\n",
    "        'timestamp': dt.datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Cell 1: STFT and energy computation\n",
    "        log_file.write(f\"\\n--- Cell 1: STFT and Energy Computation ---\\n\")\n",
    "        window_length = 256\n",
    "        overlap = window_length // 2\n",
    "        frame_step = window_length - overlap\n",
    "        \n",
    "        f, t, Zxx = stft(signal, fs=FS, nperseg=window_length, noverlap=overlap)\n",
    "        energy_per_freq = np.sum(np.abs(Zxx)**2, axis=1)\n",
    "        \n",
    "        log_file.write(f\"STFT shape: {Zxx.shape}\\n\")\n",
    "        log_file.write(f\"Frequency bins: {len(f)}, Time frames: {len(t)}\\n\")\n",
    "        log_file.flush()\n",
    "        \n",
    "        results['stft'] = {\n",
    "            'frequencies': f,\n",
    "            'time_frames': t,\n",
    "            'spectrogram': Zxx,\n",
    "            'energy_per_freq': energy_per_freq,\n",
    "            'window_length': window_length,\n",
    "            'overlap': overlap,\n",
    "            'frame_step': frame_step\n",
    "        }\n",
    "        \n",
    "        # Cell 2: First k-means (k=2) to separate signal from noise\n",
    "        log_file.write(f\"\\n--- Cell 2: First k-means (k=2) ---\\n\")\n",
    "        energy_reshaped = energy_per_freq.reshape(-1, 1)\n",
    "        kmeans_energy = KMeans(n_clusters=2, random_state=0, n_init=10)\n",
    "        energy_labels = kmeans_energy.fit_predict(energy_reshaped)\n",
    "        \n",
    "        cluster_centers = kmeans_energy.cluster_centers_.flatten()\n",
    "        signal_cluster_idx = np.argmax(cluster_centers)\n",
    "        high_energy_freq_indices = np.where(energy_labels == signal_cluster_idx)[0]\n",
    "        \n",
    "        log_file.write(f\"High-energy (signal) bins: {len(high_energy_freq_indices)}\\n\")\n",
    "        log_file.flush()\n",
    "        \n",
    "        results['energy_clustering'] = {\n",
    "            'labels': energy_labels,\n",
    "            'cluster_centers': cluster_centers,\n",
    "            'signal_cluster_idx': int(signal_cluster_idx),\n",
    "            'high_energy_freq_indices': high_energy_freq_indices\n",
    "        }\n",
    "        \n",
    "        # Cell 3: Second k-means (k=8) for frequency clustering\n",
    "        log_file.write(f\"\\n--- Cell 3: Second k-means (k=8) ---\\n\")\n",
    "        high_energy_freqs = f[high_energy_freq_indices]\n",
    "        high_energy_energies = energy_per_freq[high_energy_freq_indices]\n",
    "        \n",
    "        # adapt k dynamically if we have fewer samples than clusters\n",
    "        n_high_energy = len(high_energy_freq_indices)\n",
    "        k_freq = min(8, max(1, n_high_energy))  # at least 1 cluster, at most 8, but not more than samples\n",
    "        \n",
    "        if n_high_energy < 2:\n",
    "            log_file.write(f\"Warning: Only {n_high_energy} high-energy frequency bins found, skipping frequency clustering\\n\")\n",
    "            major_freq_clusters = []\n",
    "        else:\n",
    "            freq_normalized = (high_energy_freqs - high_energy_freqs.min()) / (high_energy_freqs.max() - high_energy_freqs.min() + 1e-10)\n",
    "            energy_normalized = (high_energy_energies - high_energy_energies.min()) / (high_energy_energies.max() - high_energy_energies.min() + 1e-10)\n",
    "            features_2d = np.column_stack([freq_normalized, energy_normalized])\n",
    "            \n",
    "            kmeans_freq = KMeans(n_clusters=k_freq, random_state=0, n_init=10)\n",
    "            freq_cluster_labels = kmeans_freq.fit_predict(features_2d)\n",
    "            \n",
    "            major_freq_clusters = []\n",
    "            for cluster_id in range(k_freq):\n",
    "                cluster_mask = freq_cluster_labels == cluster_id\n",
    "                cluster_freq_indices = high_energy_freq_indices[cluster_mask]\n",
    "                cluster_freqs = high_energy_freqs[cluster_mask]\n",
    "                cluster_energies = high_energy_energies[cluster_mask]\n",
    "                \n",
    "                if len(cluster_freq_indices) > 0:  # only add non-empty clusters\n",
    "                    cluster_center_freq = np.mean(cluster_freqs)\n",
    "                    cluster_center_energy = np.mean(cluster_energies)\n",
    "                    \n",
    "                    major_freq_clusters.append({\n",
    "                        'cluster_id': cluster_id,\n",
    "                        'center_freq': cluster_center_freq,\n",
    "                        'center_energy': cluster_center_energy,\n",
    "                        'freq_indices': cluster_freq_indices,\n",
    "                        'freqs': cluster_freqs,\n",
    "                        'energies': cluster_energies\n",
    "                    })\n",
    "        \n",
    "        # filter clusters\n",
    "        major_freq_clusters = [c for c in major_freq_clusters if len(c['freq_indices']) > 1]\n",
    "        dtmf_freq_range = (500, 1800)\n",
    "        major_freq_clusters = [c for c in major_freq_clusters \n",
    "                              if dtmf_freq_range[0] <= c['center_freq'] <= dtmf_freq_range[1]]\n",
    "        major_freq_clusters.sort(key=lambda x: x['center_freq'])\n",
    "        \n",
    "        log_file.write(f\"Number of major frequency clusters: {len(major_freq_clusters)}\\n\")\n",
    "        for i, cluster in enumerate(major_freq_clusters):\n",
    "            log_file.write(f\"  Cluster {i}: center={cluster['center_freq']:.1f} Hz, \"\n",
    "                          f\"n_bins={len(cluster['freq_indices'])}\\n\")\n",
    "        log_file.flush()\n",
    "        \n",
    "        results['freq_clustering'] = {\n",
    "            'n_clusters': len(major_freq_clusters),\n",
    "            'clusters': major_freq_clusters\n",
    "        }\n",
    "        \n",
    "        # Cell 4: Changepoint detection\n",
    "        log_file.write(f\"\\n--- Cell 4: Changepoint Detection ---\\n\")\n",
    "        t_max = len(t)\n",
    "        all_changepoints = []\n",
    "        \n",
    "        for cluster in major_freq_clusters:\n",
    "            freq_indices = cluster['freq_indices']\n",
    "            freq_cp_results = []\n",
    "            \n",
    "            for freq_idx in freq_indices:\n",
    "                freq_energy = np.abs(Zxx[freq_idx, :])**2\n",
    "                sigma_est = np.std(freq_energy)\n",
    "                pen_bic = 2 * sigma_est**2 * np.log(t_max)\n",
    "                \n",
    "                algo = rpt.Pelt(model=\"l2\", jump=1)\n",
    "                predicted_bkps = algo.fit_predict(freq_energy, pen=pen_bic)\n",
    "                signal_bkps = [min(int(idx * frame_step), len(signal)) \n",
    "                              for idx in predicted_bkps[:-1]]\n",
    "                \n",
    "                freq_cp_results.append({\n",
    "                    'freq_idx': freq_idx,\n",
    "                    'freq_value': f[freq_idx],\n",
    "                    'changepoints': signal_bkps,\n",
    "                    'frame_bkps': predicted_bkps[:-1],\n",
    "                    'n_cps': len(signal_bkps),\n",
    "                    'energy_signal': freq_energy\n",
    "                })\n",
    "            \n",
    "            best_freq_result = min(freq_cp_results, key=lambda x: x['n_cps'])\n",
    "            \n",
    "            all_changepoints.append({\n",
    "                'cluster_id': cluster['cluster_id'],\n",
    "                'center_freq': cluster['center_freq'],\n",
    "                'selected_freq': best_freq_result['freq_value'],\n",
    "                'selected_freq_idx': best_freq_result['freq_idx'],\n",
    "                'changepoints': best_freq_result['changepoints'],\n",
    "                'frame_bkps': best_freq_result['frame_bkps'],\n",
    "                'energy_signal': best_freq_result['energy_signal'],\n",
    "                'n_cps': best_freq_result['n_cps']\n",
    "            })\n",
    "            \n",
    "            log_file.write(f\"Cluster {cluster['cluster_id']}: selected freq {best_freq_result['freq_value']:.1f} Hz \"\n",
    "                          f\"with {best_freq_result['n_cps']} CPs\\n\")\n",
    "        \n",
    "        log_file.flush()\n",
    "        \n",
    "        results['changepoints'] = all_changepoints\n",
    "        \n",
    "        # group into low and high frequency clusters\n",
    "        dtmf_low_freqs = [697, 770, 852, 941]\n",
    "        dtmf_high_freqs = [1209, 1336, 1477, 1633]\n",
    "        freq_threshold = 1000\n",
    "        \n",
    "        low_freq_clusters = [c for c in all_changepoints if c['selected_freq'] < freq_threshold]\n",
    "        high_freq_clusters = [c for c in all_changepoints if c['selected_freq'] >= freq_threshold]\n",
    "        \n",
    "        log_file.write(f\"\\nLow frequency clusters: {len(low_freq_clusters)}\\n\")\n",
    "        log_file.write(f\"High frequency clusters: {len(high_freq_clusters)}\\n\")\n",
    "        log_file.flush()\n",
    "        \n",
    "        # Cell 6: Distribution analysis and filtering\n",
    "        log_file.write(f\"\\n--- Cell 6: Distribution Analysis ---\\n\")\n",
    "        all_cp_times_list = []\n",
    "        for cp_dict in all_changepoints:\n",
    "            for cp_sample in cp_dict['changepoints']:\n",
    "                all_cp_times_list.append(cp_sample)\n",
    "        \n",
    "        ordered_cps = sorted(set(all_cp_times_list))\n",
    "        time_periods = []\n",
    "        for i in range(len(ordered_cps) - 1):\n",
    "            period_samples = ordered_cps[i+1] - ordered_cps[i]\n",
    "            period_seconds = period_samples / FS\n",
    "            time_periods.append({\n",
    "                'start_cp': ordered_cps[i],\n",
    "                'end_cp': ordered_cps[i+1],\n",
    "                'duration_samples': period_samples,\n",
    "                'duration_seconds': period_seconds,\n",
    "                'index': i\n",
    "            })\n",
    "        \n",
    "        period_durations = [p['duration_seconds'] for p in time_periods]\n",
    "        q25 = np.percentile(period_durations, 25)\n",
    "        q75 = np.percentile(period_durations, 75)\n",
    "        iqr = q75 - q25\n",
    "        lower_bound = q25 - 1.5 * iqr\n",
    "        \n",
    "        lower_outliers = [p for p in time_periods if p['duration_seconds'] < lower_bound]\n",
    "        lower_outliers_sorted = sorted(lower_outliers, key=lambda x: x['duration_seconds'])\n",
    "        \n",
    "        magic_threshold = 0.4\n",
    "        filtered_periods = time_periods.copy()\n",
    "        removed_outliers = []\n",
    "        \n",
    "        for outlier in lower_outliers_sorted:\n",
    "            test_duration = sum(p['duration_seconds'] for p in filtered_periods \n",
    "                               if p['index'] != outlier['index'])\n",
    "            if test_duration > magic_threshold:\n",
    "                filtered_periods = [p for p in filtered_periods if p['index'] != outlier['index']]\n",
    "                removed_outliers.append(outlier)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        log_file.write(f\"Original periods: {len(time_periods)}\\n\")\n",
    "        log_file.write(f\"Removed outliers: {len(removed_outliers)}\\n\")\n",
    "        log_file.write(f\"Filtered periods: {len(filtered_periods)}\\n\")\n",
    "        log_file.flush()\n",
    "        \n",
    "        results['period_analysis'] = {\n",
    "            'time_periods': time_periods,\n",
    "            'filtered_periods': filtered_periods,\n",
    "            'removed_outliers': removed_outliers,\n",
    "            'statistics': {\n",
    "                'q25': float(q25),\n",
    "                'q75': float(q75),\n",
    "                'iqr': float(iqr),\n",
    "                'lower_bound': float(lower_bound)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Cell 7: Period-symbol matching\n",
    "        log_file.write(f\"\\n--- Cell 7: Period-Symbol Matching ---\\n\")\n",
    "        n_symbols = len(ground_truth_symbols)\n",
    "        \n",
    "        # select N biggest periods\n",
    "        selected_periods = sorted(filtered_periods, key=lambda x: x['duration_seconds'], reverse=True)[:n_symbols]\n",
    "        periods_ordered_by_time = sorted(selected_periods, key=lambda x: x['start_cp'])\n",
    "        \n",
    "        log_file.write(f\"Selected {len(selected_periods)} periods for {n_symbols} symbols\\n\")\n",
    "        \n",
    "        # use the matching functions (simplified version)\n",
    "        complete_matches = []\n",
    "        for i, (period, symbol) in enumerate(zip(periods_ordered_by_time, ground_truth_symbols)):\n",
    "            # find active frequencies using the improved function\n",
    "            active_freqs = find_active_frequencies_in_period(\n",
    "                period, low_freq_clusters, high_freq_clusters, frame_step,\n",
    "                energy_threshold_ratio=0.05, cp_tolerance=3000\n",
    "            )\n",
    "            active_low = active_freqs['low_clusters']\n",
    "            active_high = active_freqs['high_clusters']\n",
    "            \n",
    "            primary_low = active_freqs['low_freqs'][0] if active_freqs['low_freqs'] else None\n",
    "            primary_high = active_freqs['high_freqs'][0] if active_freqs['high_freqs'] else None\n",
    "            \n",
    "            # verify symbol\n",
    "            verified_symbol = None\n",
    "            if primary_low and primary_high:\n",
    "                def freq_to_dtmf_index(freq, freq_list):\n",
    "                    distances = [abs(freq - dtmf_f) for dtmf_f in freq_list]\n",
    "                    min_idx = np.argmin(distances)\n",
    "                    min_dist = distances[min_idx]\n",
    "                    return min_idx if min_dist < 50 else None\n",
    "                \n",
    "                dtmf_symbols = [\n",
    "                    ['1', '2', '3', 'A'],\n",
    "                    ['4', '5', '6', 'B'],\n",
    "                    ['7', '8', '9', 'C'],\n",
    "                    ['*', '0', '#', 'D']\n",
    "                ]\n",
    "                \n",
    "                low_idx = freq_to_dtmf_index(primary_low, dtmf_low_freqs)\n",
    "                high_idx = freq_to_dtmf_index(primary_high, dtmf_high_freqs)\n",
    "                if low_idx is not None and high_idx is not None:\n",
    "                    verified_symbol = dtmf_symbols[low_idx][high_idx]\n",
    "            \n",
    "            match = {\n",
    "                'period': period,\n",
    "                'assigned_symbol': symbol,\n",
    "                'verified_symbol': verified_symbol,\n",
    "                'primary_low_freq': primary_low,\n",
    "                'primary_high_freq': primary_high,\n",
    "                'active_low_freqs': [f['freq'] for f in active_low],\n",
    "                'active_high_freqs': [f['freq'] for f in active_high],\n",
    "                'match_index': i,\n",
    "                'symbol_match': (symbol == verified_symbol) if verified_symbol else False\n",
    "            }\n",
    "            complete_matches.append(match)\n",
    "            \n",
    "            # format frequencies safely (handle None values)\n",
    "            low_freq_str = f\"{primary_low:.0f}\" if primary_low is not None else \"None\"\n",
    "            high_freq_str = f\"{primary_high:.0f}\" if primary_high is not None else \"None\"\n",
    "            freq_pair_str = f\"{low_freq_str}+{high_freq_str}Hz\" if (primary_low is not None and primary_high is not None) else \"no freq pair\"\n",
    "            \n",
    "            log_file.write(f\"Match {i+1}: '{symbol}' -> period [{period['start_cp']/FS:.3f}, {period['end_cp']/FS:.3f}]s, \"\n",
    "                          f\"freqs: {freq_pair_str}, verified: '{verified_symbol}', \"\n",
    "                          f\"match: {'✓' if match['symbol_match'] else '✗'}\\n\")\n",
    "        \n",
    "        log_file.flush()\n",
    "        \n",
    "        results['matches'] = complete_matches\n",
    "        results['success'] = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_file.write(f\"\\nERROR processing signal {signal_idx}: {str(e)}\\n\")\n",
    "        import traceback\n",
    "        log_file.write(traceback.format_exc())\n",
    "        results['success'] = False\n",
    "        results['error'] = str(e)\n",
    "        log_file.flush()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# process all signals\n",
    "print(f\"Processing {len(X_train)} signals...\")\n",
    "print(f\"Results will be saved to: {output_dir}\")\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    signal = X_train[i]\n",
    "    ground_truth = y_train[i]\n",
    "    \n",
    "    # create log file\n",
    "    log_path = os.path.join(output_dir, f\"log_{i}.txt\")\n",
    "    with open(log_path, 'w') as log_file:\n",
    "        log_file.write(f\"DTMF Detection Log for Signal {i}\\n\")\n",
    "        log_file.write(f\"Timestamp: {dt.datetime.now().isoformat()}\\n\")\n",
    "        \n",
    "        # process signal\n",
    "        results = process_single_signal(signal, ground_truth, i, log_file)\n",
    "        \n",
    "        # save NPZ file\n",
    "        npz_path = os.path.join(output_dir, f\"results_{i}.npz\")\n",
    "        \n",
    "        # prepare data for NPZ (convert to numpy arrays where possible)\n",
    "        npz_data = {\n",
    "            'signal': signal,\n",
    "            'signal_idx': np.array([i]),\n",
    "            'ground_truth_symbols': np.array(ground_truth, dtype=object),\n",
    "            'success': np.array([results.get('success', False)])\n",
    "        }\n",
    "        \n",
    "        if 'stft' in results:\n",
    "            npz_data['stft_frequencies'] = results['stft']['frequencies']\n",
    "            npz_data['stft_time_frames'] = results['stft']['time_frames']\n",
    "            npz_data['stft_spectrogram'] = results['stft']['spectrogram']\n",
    "            npz_data['energy_per_freq'] = results['stft']['energy_per_freq']\n",
    "        \n",
    "        if 'changepoints' in results:\n",
    "            # save changepoints as separate arrays for each cluster\n",
    "            for j, cp in enumerate(results['changepoints']):\n",
    "                npz_data[f'changepoints_cluster_{j}'] = np.array(cp['changepoints'])\n",
    "                npz_data[f'changepoint_freq_cluster_{j}'] = np.array([cp['selected_freq']])\n",
    "        \n",
    "        if 'period_analysis' in results and 'filtered_periods' in results['period_analysis']:\n",
    "            filtered_periods = results['period_analysis']['filtered_periods']\n",
    "            npz_data['filtered_periods_starts'] = np.array([p['start_cp'] for p in filtered_periods])\n",
    "            npz_data['filtered_periods_ends'] = np.array([p['end_cp'] for p in filtered_periods])\n",
    "            npz_data['filtered_periods_durations'] = np.array([p['duration_seconds'] for p in filtered_periods])\n",
    "        \n",
    "        if 'matches' in results:\n",
    "            matches = results['matches']\n",
    "            npz_data['matches_assigned_symbols'] = np.array([m['assigned_symbol'] for m in matches], dtype=object)\n",
    "            npz_data['matches_verified_symbols'] = np.array([m.get('verified_symbol', '') or '' for m in matches], dtype=object)\n",
    "            npz_data['matches_low_freqs'] = np.array([m.get('primary_low_freq', 0.0) or 0.0 for m in matches])\n",
    "            npz_data['matches_high_freqs'] = np.array([m.get('primary_high_freq', 0.0) or 0.0 for m in matches])\n",
    "            npz_data['matches_period_starts'] = np.array([m['period']['start_cp'] for m in matches])\n",
    "            npz_data['matches_period_ends'] = np.array([m['period']['end_cp'] for m in matches])\n",
    "            npz_data['matches_symbol_match'] = np.array([m['symbol_match'] for m in matches])\n",
    "        \n",
    "        np.savez_compressed(npz_path, **npz_data)\n",
    "        \n",
    "        # save JSON file\n",
    "        json_path = os.path.join(output_dir, f\"results_{i}.json\")\n",
    "        json_results = {\n",
    "            'signal_idx': results['signal_idx'],\n",
    "            'signal_length': results['signal_length'],\n",
    "            'ground_truth_symbols': results['ground_truth_symbols'],\n",
    "            'timestamp': results['timestamp'],\n",
    "            'success': results.get('success', False),\n",
    "            'stft_params': {\n",
    "                'window_length': results.get('stft', {}).get('window_length', 256),\n",
    "                'overlap': results.get('stft', {}).get('overlap', 128),\n",
    "                'frame_step': results.get('stft', {}).get('frame_step', 128)\n",
    "            },\n",
    "            'freq_clustering': {\n",
    "                'n_clusters': results.get('freq_clustering', {}).get('n_clusters', 0),\n",
    "                'cluster_centers': [c['center_freq'] for c in results.get('freq_clustering', {}).get('clusters', [])]\n",
    "            },\n",
    "            'changepoints_summary': [\n",
    "                {\n",
    "                    'cluster_id': cp['cluster_id'],\n",
    "                    'selected_freq': float(cp['selected_freq']),\n",
    "                    'n_changepoints': cp['n_cps'],\n",
    "                    'changepoints': [int(x) for x in cp['changepoints']]\n",
    "                }\n",
    "                for cp in results.get('changepoints', [])\n",
    "            ],\n",
    "            'period_analysis': {\n",
    "                'n_original_periods': len(results.get('period_analysis', {}).get('time_periods', [])),\n",
    "                'n_filtered_periods': len(results.get('period_analysis', {}).get('filtered_periods', [])),\n",
    "                'n_removed_outliers': len(results.get('period_analysis', {}).get('removed_outliers', [])),\n",
    "                'statistics': results.get('period_analysis', {}).get('statistics', {})\n",
    "            },\n",
    "            'matches': [\n",
    "                {\n",
    "                    'match_index': m['match_index'],\n",
    "                    'assigned_symbol': m['assigned_symbol'],\n",
    "                    'verified_symbol': m.get('verified_symbol'),\n",
    "                    'primary_low_freq': float(m.get('primary_low_freq', 0)) if m.get('primary_low_freq') else None,\n",
    "                    'primary_high_freq': float(m.get('primary_high_freq', 0)) if m.get('primary_high_freq') else None,\n",
    "                    'period_start': float(m['period']['start_cp'] / FS),\n",
    "                    'period_end': float(m['period']['end_cp'] / FS),\n",
    "                    'period_duration': float(m['period']['duration_seconds']),\n",
    "                    'symbol_match': m['symbol_match']\n",
    "                }\n",
    "                for m in results.get('matches', [])\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        if 'error' in results:\n",
    "            json_results['error'] = results['error']\n",
    "        \n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(json_results, f, indent=2)\n",
    "        \n",
    "        log_file.write(f\"\\n{'='*80}\\n\")\n",
    "        log_file.write(f\"Results saved to:\\n\")\n",
    "        log_file.write(f\"  NPZ: {npz_path}\\n\")\n",
    "        log_file.write(f\"  JSON: {json_path}\\n\")\n",
    "        log_file.write(f\"  Log: {log_path}\\n\")\n",
    "        log_file.write(f\"{'='*80}\\n\")\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Processed {i + 1}/{len(X_train)} signals...\")\n",
    "\n",
    "print(f\"\\nCompleted! All results saved to {output_dir}\")\n",
    "\n",
    "# create summary statistics\n",
    "print(\"\\nGenerating summary statistics...\")\n",
    "summary = {\n",
    "    'total_signals': len(X_train),\n",
    "    'timestamp': dt.datetime.now().isoformat(),\n",
    "    'signals_processed': [],\n",
    "    'overall_statistics': {\n",
    "        'total_matches': 0,\n",
    "        'correct_matches': 0,\n",
    "        'signals_with_errors': 0\n",
    "    }\n",
    "}\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    json_path = os.path.join(output_dir, f\"results_{i}.json\")\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            summary['signals_processed'].append({\n",
    "                'signal_idx': i,\n",
    "                'success': data.get('success', False),\n",
    "                'n_matches': len(data.get('matches', [])),\n",
    "                'n_correct': sum(1 for m in data.get('matches', []) if m.get('symbol_match', False))\n",
    "            })\n",
    "            if data.get('success', False):\n",
    "                summary['overall_statistics']['total_matches'] += len(data.get('matches', []))\n",
    "                summary['overall_statistics']['correct_matches'] += sum(1 for m in data.get('matches', []) if m.get('symbol_match', False))\n",
    "            else:\n",
    "                summary['overall_statistics']['signals_with_errors'] += 1\n",
    "\n",
    "summary['overall_statistics']['accuracy'] = (\n",
    "    summary['overall_statistics']['correct_matches'] / summary['overall_statistics']['total_matches']\n",
    "    if summary['overall_statistics']['total_matches'] > 0 else 0.0\n",
    ")\n",
    "\n",
    "# save summary\n",
    "summary_path = os.path.join(output_dir, 'summary.json')\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"Summary saved to: {summary_path}\")\n",
    "print(f\"\\nOverall Statistics:\")\n",
    "print(f\"  Total signals: {summary['overall_statistics']['total_matches']}\")\n",
    "print(f\"  Correct matches: {summary['overall_statistics']['correct_matches']}\")\n",
    "print(f\"  Accuracy: {summary['overall_statistics']['accuracy']:.2%}\")\n",
    "print(f\"  Signals with errors: {summary['overall_statistics']['signals_with_errors']}\")\n",
    "\n",
    "# build global frequency dataset: ground truth symbols + detected frequency pairs for each signal\n",
    "print(\"\\nBuilding frequency dataset (ground truth symbols + detected frequency pairs)...\")\n",
    "freq_dataset = {\n",
    "    'total_signals': len(X_train),\n",
    "    'timestamp': dt.datetime.now().isoformat(),\n",
    "    'signals': [],\n",
    "    'overall': {\n",
    "        'total_pairs': 0,\n",
    "        'signals_with_at_least_one_pair': 0\n",
    "    }\n",
    "}\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    json_path = os.path.join(output_dir, f\"results_{i}.json\")\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        pairs = []\n",
    "        for m in data.get('matches', []):\n",
    "            low = m.get('primary_low_freq')\n",
    "            high = m.get('primary_high_freq')\n",
    "            if (low is not None) and (high is not None):\n",
    "                pairs.append({\n",
    "                    'low_freq': float(low),\n",
    "                    'high_freq': float(high)\n",
    "                })\n",
    "        \n",
    "        freq_dataset['signals'].append({\n",
    "            'signal_idx': i,\n",
    "            'ground_truth_symbols': data.get('ground_truth_symbols', []),\n",
    "            'detected_pairs': pairs\n",
    "        })\n",
    "        \n",
    "        freq_dataset['overall']['total_pairs'] += len(pairs)\n",
    "        if len(pairs) > 0:\n",
    "            freq_dataset['overall']['signals_with_at_least_one_pair'] += 1\n",
    "\n",
    "if freq_dataset['signals']:\n",
    "    freq_dataset['overall']['average_pairs_per_signal'] = (\n",
    "        freq_dataset['overall']['total_pairs'] / len(freq_dataset['signals'])\n",
    "    )\n",
    "else:\n",
    "    freq_dataset['overall']['average_pairs_per_signal'] = 0.0\n",
    "\n",
    "freq_dataset_path = os.path.join(output_dir, 'freq_dataset.json')\n",
    "with open(freq_dataset_path, 'w') as f:\n",
    "    json.dump(freq_dataset, f, indent=2)\n",
    "\n",
    "print(f\"\\nFrequency dataset saved to: {freq_dataset_path}\")\n",
    "print(f\"  Total \\\"true\\\" frequency pairs (both low+high found): {freq_dataset['overall']['total_pairs']}\")\n",
    "print(f\"  Signals with at least one pair: {freq_dataset['overall']['signals_with_at_least_one_pair']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288f955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
